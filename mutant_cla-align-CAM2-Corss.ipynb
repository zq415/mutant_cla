{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import copy\n",
    "import Levenshtein\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def read_mutant_txt(path):\n",
    "    name_list = []\n",
    "    fo = open(path)\n",
    "    for line in fo:\n",
    "        striped_line = line.strip('\\n')\n",
    "        if striped_line != '':\n",
    "            name_list.append(striped_line)\n",
    "    return name_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_names = read_mutant_txt('mutant_imgs.txt')\n",
    "data_base_path = '/scratch/zq415/grammar_cor/mutant_detect/data'\n",
    "data_folder_list = ['20180419_newdata_nii_with_filtered', 'new_data_20180522_nii', 'organized_data_nii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant_label[i] = (i, 1, bv_base_name, label_resized, img_resized, img_path[1])\n",
    "\n",
    "save_name = 'All_data_112_64_64.pickle'\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'data',save_name), \"rb\") as input_file:\n",
    "    all_train_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  0 25\n",
      "fold  1 18\n",
      "fold  2 17\n",
      "fold  3 13\n",
      "fold  4 15\n",
      "fold  5 15\n"
     ]
    }
   ],
   "source": [
    "mutant_group = [(9,10), (12,13,14), (16,17,18,19), (36,37), (38,39), (42,43), (44,45,46,47), (48,49,50,51), (52,53), (54,55),\n",
    "(56,57,58), (59,60,61), (63,64), (66,67,68), (69,70,71), (73,74), (75,76), (77,78,79), (80,81,82,83,84,85,86,87),\n",
    "(89,90), (91,92), (93,94), (95,96,97), (98,99), (100,101,102)]\n",
    "\n",
    "group_list = []\n",
    "for one_group in mutant_group:\n",
    "    for ii in range(len(one_group)):\n",
    "        group_list.append(one_group[ii])\n",
    "single_mutant = [i for i in range(len(mutant_names)) if i not in group_list]\n",
    "\n",
    "test_mut_names = {}\n",
    "for fold_num in range(6):\n",
    "    test_mut_names[fold_num] = []\n",
    "    for i in range(fold_num,len(mutant_group),6):\n",
    "        for ii in range(len(mutant_group[i])):\n",
    "            test_mut_names[fold_num].append(mutant_names[mutant_group[i][ii]])\n",
    "\n",
    "    for i in range(fold_num,len(single_mutant),6):\n",
    "        test_mut_names[fold_num].append(mutant_names[single_mutant[i]])\n",
    "\n",
    "    print('fold ', fold_num, len(test_mut_names[fold_num]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_img = {}\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] in mutant_names:\n",
    "        mutant_img[all_train_data[i][2]] = (all_train_data[i][3], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_names = []\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] not in mutant_names:\n",
    "        normal_names.append(all_train_data[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_group = []\n",
    "indexed_list = []\n",
    "group_num = 0\n",
    "for i in range(len(normal_names)):\n",
    "    if i not in indexed_list:       \n",
    "        normal_group.append([normal_names[i]])\n",
    "        indexed_list.append(i)\n",
    "        for ii in range(i+1,len(normal_names)):\n",
    "            if ii not in indexed_list and Levenshtein.distance(normal_names[i], normal_names[ii]) < 2:\n",
    "                normal_group[group_num].append(normal_names[ii])\n",
    "                indexed_list.append(ii)\n",
    "                \n",
    "        group_num += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  0 76\n",
      "fold  1 91\n",
      "fold  2 72\n",
      "fold  3 67\n",
      "fold  4 71\n",
      "fold  5 86\n"
     ]
    }
   ],
   "source": [
    "test_normal_names = {}\n",
    "for fold_num in range(6):\n",
    "    test_normal_names[fold_num] = []\n",
    "    for i in range(fold_num,len(normal_group),6):\n",
    "        for ii in range(len(normal_group[i])):\n",
    "            test_normal_names[fold_num].append(normal_group[i][ii])\n",
    "\n",
    "    print('fold ', fold_num, len(test_normal_names[fold_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_img = {}\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] not in mutant_names:\n",
    "        normal_img[all_train_data[i][5]] = (all_train_data[i][3], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  0 101\n",
      "fold:  1 109\n",
      "fold:  2 89\n",
      "fold:  3 80\n",
      "fold:  4 86\n",
      "fold:  5 101\n"
     ]
    }
   ],
   "source": [
    "data_folds = [[],[],[],[],[],[]]\n",
    "\n",
    "for fold_num in range(6):\n",
    "    \n",
    "    for i in range(len(test_mut_names[fold_num])):\n",
    "        data_folds[fold_num].append(mutant_img[test_mut_names[fold_num][i]])\n",
    "        \n",
    "    for i in range(len(test_normal_names[fold_num])):\n",
    "        data_folds[fold_num].append(normal_img[test_normal_names[fold_num][i]])\n",
    "\n",
    "    print('fold: ', fold_num, len(data_folds[fold_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_nft = nib.Nifti1Image(np.squeeze(all_train_data[193]),np.eye(4))\n",
    "#img_save_data_path = './img/mul_img.nii'\n",
    "#nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Mouse_sub_volumes(Dataset):\n",
    "    \"\"\"Mouse sub-volumes BV dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, all_data , transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            all_whole_volumes: Contain all the padded whole BV volumes as a dic\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.all_data = all_data\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self, num):\n",
    "        \n",
    "        current_img, label = self.all_data[num]\n",
    "        \n",
    "        img = np.float32(current_img[np.newaxis,...])\n",
    "        sample = {'image': img, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Flip the image for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,ori_probability=0.20):\n",
    "        self.ori_probability = ori_probability\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['image'], sample['label']\n",
    "            random_choise1=random.choice([1,2,3,4,5,6,7,8])\n",
    "            img[0,...] = {1: lambda x: x,\n",
    "                          2: lambda x: x[::-1,:,:],\n",
    "                          3: lambda x: x[:,::-1,:],\n",
    "                          4: lambda x: x[:,:,::-1],\n",
    "                          5: lambda x: x[::-1,::-1,:],\n",
    "                          6: lambda x: x[::-1,:,::-1],\n",
    "                          7: lambda x: x[:,::-1,::-1],\n",
    "                          8: lambda x: x[::-1,::-1,::-1]\n",
    "                          }[random_choise1](img[0,...])\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    def __init__(self,conv_drop_rate=0.10,linear_drop_rate=0.2):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=12, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv1_bn = nn.BatchNorm3d(12)\n",
    "        self.conv2 = nn.Conv3d(in_channels=12, out_channels=12, kernel_size=3,stride=1,padding=2, dilation=2)\n",
    "        self.conv2_bn = nn.BatchNorm3d(12)\n",
    "        self.pool1 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout1 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=12, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv3_bn = nn.BatchNorm3d(24)\n",
    "        self.conv4 = nn.Conv3d(in_channels=24, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv4_bn = nn.BatchNorm3d(24)\n",
    "        self.pool2 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout2 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv5 = nn.Conv3d(in_channels=24, out_channels=48, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv5_bn = nn.BatchNorm3d(48)\n",
    "        self.conv6 = nn.Conv3d(in_channels=48, out_channels=48, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv6_bn = nn.BatchNorm3d(48)\n",
    "        self.pool3 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout3 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv7 = nn.Conv3d(in_channels=48, out_channels=72, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv7_bn = nn.BatchNorm3d(72)\n",
    "        self.conv8 = nn.Conv3d(in_channels=72, out_channels=72, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv8_bn = nn.BatchNorm3d(72)\n",
    "        self.pool4 = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.dropout4 = nn.Dropout3d(linear_drop_rate)\n",
    "        self.pool5 = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.dropout5 = nn.Dropout3d(linear_drop_rate)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(144, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1_bn(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(self.pool1(self.conv2_bn(F.relu(self.conv2(x)))))\n",
    "        \n",
    "        x = self.conv3_bn(F.relu(self.conv3(x)))\n",
    "        x = self.dropout2(self.pool2(self.conv4_bn(F.relu(self.conv4(x)))))\n",
    "        \n",
    "        x = self.conv5_bn(F.relu(self.conv5(x)))\n",
    "        x = self.dropout3(self.pool3(self.conv6_bn(F.relu(self.conv6(x)))))\n",
    "        \n",
    "        x = self.conv7_bn(F.relu(self.conv7(x)))\n",
    "        x = self.conv8_bn(F.relu(self.conv8(x)))\n",
    "        \n",
    "        x1 = self.dropout4(self.pool4(x))\n",
    "        x2 = self.dropout5(self.pool5(x))\n",
    "        \n",
    "        x1 = x1.view(-1, 72)\n",
    "        x2 = x2.view(-1, 72)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        #x = self.dropout5(self.fc1_bn(F.relu(self.fc1(x))))\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        i_batch += 1\n",
    "        if i_batch % 10 == 0:\n",
    "            print(\"epoch {}, batch {}, current loss {}\".format(epoch+1,i_batch,running_loss/10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy()))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels\n",
    "\n",
    "def get_confusion_matrix(true_predicted_labels):\n",
    "    cross_table = np.zeros([2,2])\n",
    "    mut_to_nor = []\n",
    "    nor_to_mul = []\n",
    "    test_dic = true_predicted_labels\n",
    "    for i in range(len(test_dic)):\n",
    "        if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "            cross_table[0,0] += 1\n",
    "        elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "            cross_table[0,1] += 1\n",
    "            mut_to_nor.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "            cross_table[1,0] += 1\n",
    "            nor_to_mul.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "            cross_table[1,1] += 1\n",
    "    print(cross_table)\n",
    "    print(mut_to_nor)\n",
    "    print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "465"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 355358 parameters in the model\n",
      "choose SGD as optimizer\n",
      "torch.Size([12, 1, 112, 64, 64])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-b6456b721ad8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     33\u001b[0m         \u001b[0mMouse_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMouse_sub_volumes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCompose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mFlip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMouse_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m12\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fold {}, epoch {} train accuracy: '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfold_num\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-b23349a1e977>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# forward + backward + optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-895470f75009>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/pyenv/py3.6.3/lib/python3.6/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    419\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m         return F.conv3d(input, self.weight, self.bias, self.stride,\n\u001b[0;32m--> 421\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CuDNN error: CUDNN_STATUS_NOT_SUPPORTED. This error may appear if you passed in a non-contiguous input."
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "\n",
    "num_epochs = 100\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([3.5,1.0]).to(device))\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "print('choose SGD as optimizer')\n",
    "#optimizer = optim.Adam(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "#print('choose Adam as optimizer')\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "for fold_num in range(6):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    for current_fold in range(6):\n",
    "        if current_fold == fold_num:\n",
    "            for i in range(len(data_folds[current_fold])):\n",
    "                test_data.append((data_folds[current_fold][i][0] - 0.5, data_folds[current_fold][i][1]))\n",
    "        else:\n",
    "            for i in range(len(data_folds[current_fold])):\n",
    "                train_data.append((data_folds[current_fold][i][0] - 0.5, data_folds[current_fold][i][1]))\n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "\n",
    "        Mouse_dataset = Mouse_sub_volumes(train_data, transform=transforms.Compose([Flip()]))\n",
    "        dataloader = DataLoader(Mouse_dataset, batch_size=12, shuffle=True, num_workers=4, drop_last = True)\n",
    "        train(net, device, dataloader, optimizer, criterion, epoch)\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print('fold {}, epoch {} train accuracy: '.format(fold_num, epoch+1))\n",
    "            train_Mouse_dataset = Mouse_sub_volumes(train_data)\n",
    "            train_dataloader = DataLoader(train_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "            train_dic = test(net, device, train_dataloader)\n",
    "            get_confusion_matrix(train_dic)\n",
    "\n",
    "            print(\"-------------------\")\n",
    "            print('fold {}, epoch {} test accuracy: '.format(fold_num, epoch+1))\n",
    "            test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "            test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "            test_dic = test(net, device, test_dataloader)\n",
    "            get_confusion_matrix(test_dic)\n",
    "\n",
    "            torch.save(net.state_dict(), './model/mut_clas_2019_01_30_e{}_global3_fold{}.pth'.format(epoch+1,fold_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 355358 parameters in the model\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_probability(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            outputs = F.softmax(outputs)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy(), outputs.cpu().numpy()[0,0], outputs.cpu().numpy()[0,1]))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), './model/mut_clas_2019_01_15.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./model/mut_clas_2019_01_29_e260_global3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('train accuracy: ')\n",
    "# Mouse_dataset = Mouse_sub_volumes(all_train_data,train_idx)\n",
    "# train_dataloader = DataLoader(Mouse_dataset, batch_size=128,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "# test(net, device, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zq415/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:96, test accuracy:0.9583333333333334, positive_acc:0.9615384615384616, negative_acc:0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy: ')\n",
    "Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dic = test_with_probability(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 17.   1.]\n",
      " [  3.  75.]]\n",
      "[0]\n",
      "[32, 38, 46]\n"
     ]
    }
   ],
   "source": [
    "cross_table = np.zeros([2,2])\n",
    "mut_to_nor = []\n",
    "nor_to_mul = []\n",
    "\n",
    "for i in range(len(test_dic)):\n",
    "    if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "        cross_table[0,0] += 1\n",
    "    elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "        cross_table[0,1] += 1\n",
    "        mut_to_nor.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "        cross_table[1,0] += 1\n",
    "        nor_to_mul.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "        cross_table[1,1] += 1\n",
    "print(cross_table)\n",
    "print(mut_to_nor)\n",
    "print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0]), array([1]), 0.0041429, 0.99585706),\n",
       " (array([1]), array([1]), 7.5907369e-06, 0.99999237),\n",
       " (array([1]), array([1]), 4.4251992e-06, 0.99999559),\n",
       " (array([1]), array([1]), 2.67421e-07, 0.99999976),\n",
       " (array([1]), array([1]), 5.5934078e-07, 0.9999994),\n",
       " (array([1]), array([1]), 5.9590968e-09, 1.0),\n",
       " (array([1]), array([1]), 5.0358584e-09, 1.0),\n",
       " (array([1]), array([1]), 3.4781678e-07, 0.99999964),\n",
       " (array([1]), array([1]), 5.1802962e-09, 1.0),\n",
       " (array([0]), array([0]), 0.53452331, 0.46547672),\n",
       " (array([1]), array([1]), 2.2590718e-09, 1.0),\n",
       " (array([1]), array([1]), 2.115409e-08, 1.0),\n",
       " (array([1]), array([1]), 2.1103202e-05, 0.9999789),\n",
       " (array([1]), array([1]), 1.3684833e-06, 0.99999869),\n",
       " (array([1]), array([1]), 2.3180987e-06, 0.99999774),\n",
       " (array([1]), array([1]), 3.4350826e-08, 1.0),\n",
       " (array([1]), array([1]), 2.7382534e-06, 0.99999726),\n",
       " (array([1]), array([1]), 2.9703788e-06, 0.99999702),\n",
       " (array([1]), array([1]), 0.00013214588, 0.9998678),\n",
       " (array([1]), array([1]), 3.0979679e-06, 0.9999969),\n",
       " (array([1]), array([1]), 7.93949e-09, 1.0),\n",
       " (array([1]), array([1]), 0.0078561604, 0.99214387),\n",
       " (array([1]), array([1]), 4.8071774e-06, 0.99999523),\n",
       " (array([1]), array([1]), 2.9852852e-06, 0.99999702),\n",
       " (array([1]), array([1]), 0.0015286832, 0.99847132),\n",
       " (array([1]), array([1]), 4.2198703e-06, 0.99999583),\n",
       " (array([1]), array([1]), 0.00011033127, 0.99988961),\n",
       " (array([1]), array([1]), 2.1836102e-05, 0.99997818),\n",
       " (array([0]), array([0]), 0.96032172, 0.039678287),\n",
       " (array([1]), array([1]), 1.5913542e-06, 0.99999845),\n",
       " (array([1]), array([1]), 2.4986666e-05, 0.99997497),\n",
       " (array([1]), array([1]), 6.9062617e-11, 1.0),\n",
       " (array([1]), array([0]), 0.81358391, 0.18641607),\n",
       " (array([1]), array([1]), 4.1658478e-07, 0.99999964),\n",
       " (array([0]), array([0]), 0.9999907, 9.3461576e-06),\n",
       " (array([0]), array([0]), 1.0, 1.7667288e-08),\n",
       " (array([0]), array([0]), 0.99994254, 5.7467438e-05),\n",
       " (array([1]), array([1]), 4.1463654e-06, 0.99999583),\n",
       " (array([1]), array([0]), 0.95469338, 0.045306604),\n",
       " (array([0]), array([0]), 0.99348795, 0.0065120482),\n",
       " (array([1]), array([1]), 2.2208232e-08, 1.0),\n",
       " (array([1]), array([1]), 7.8787195e-07, 0.99999917),\n",
       " (array([1]), array([1]), 3.5020217e-10, 1.0),\n",
       " (array([1]), array([1]), 0.00019595868, 0.99980408),\n",
       " (array([0]), array([0]), 0.99970609, 0.00029383835),\n",
       " (array([1]), array([1]), 0.0004298136, 0.99957019),\n",
       " (array([1]), array([0]), 0.9946872, 0.0053127948),\n",
       " (array([1]), array([1]), 3.7333795e-08, 1.0),\n",
       " (array([1]), array([1]), 1.4885295e-05, 0.9999851),\n",
       " (array([1]), array([1]), 9.9283113e-07, 0.99999905),\n",
       " (array([1]), array([1]), 1.9766242e-08, 1.0),\n",
       " (array([1]), array([1]), 0.0013298405, 0.99867022),\n",
       " (array([1]), array([1]), 1.0466928e-05, 0.99998951),\n",
       " (array([1]), array([1]), 2.018857e-06, 0.99999797),\n",
       " (array([1]), array([1]), 1.2079244e-08, 1.0),\n",
       " (array([1]), array([1]), 8.8912572e-07, 0.99999917),\n",
       " (array([1]), array([1]), 4.1132247e-07, 0.99999964),\n",
       " (array([1]), array([1]), 0.009162195, 0.99083775),\n",
       " (array([1]), array([1]), 6.2878635e-06, 0.99999368),\n",
       " (array([1]), array([1]), 4.1810058e-06, 0.99999583),\n",
       " (array([0]), array([0]), 0.99975663, 0.00024335462),\n",
       " (array([0]), array([0]), 0.99971014, 0.00028986999),\n",
       " (array([0]), array([0]), 0.97037518, 0.029624864),\n",
       " (array([0]), array([0]), 0.99991286, 8.7132961e-05),\n",
       " (array([1]), array([1]), 0.0003971743, 0.99960285),\n",
       " (array([1]), array([1]), 1.7582024e-05, 0.99998248),\n",
       " (array([0]), array([0]), 0.99999511, 4.8743741e-06),\n",
       " (array([1]), array([1]), 0.00048415657, 0.99951589),\n",
       " (array([1]), array([1]), 9.7314185e-08, 0.99999988),\n",
       " (array([1]), array([1]), 6.7919672e-08, 0.99999988),\n",
       " (array([1]), array([1]), 0.00010192399, 0.99989808),\n",
       " (array([1]), array([1]), 1.0063967e-07, 0.99999988),\n",
       " (array([1]), array([1]), 1.1019484e-08, 1.0),\n",
       " (array([1]), array([1]), 0.027496703, 0.97250324),\n",
       " (array([0]), array([0]), 0.9998877, 0.00011232757),\n",
       " (array([1]), array([1]), 1.3564159e-05, 0.99998641),\n",
       " (array([1]), array([1]), 3.9390288e-06, 0.99999607),\n",
       " (array([1]), array([1]), 8.0270758e-07, 0.99999917),\n",
       " (array([0]), array([0]), 0.9588322, 0.04116787),\n",
       " (array([1]), array([1]), 7.8035231e-07, 0.99999917),\n",
       " (array([1]), array([1]), 3.7335119e-06, 0.9999963),\n",
       " (array([1]), array([1]), 1.5930125e-06, 0.99999845),\n",
       " (array([1]), array([1]), 1.9996456e-08, 1.0),\n",
       " (array([1]), array([1]), 1.2552565e-09, 1.0),\n",
       " (array([1]), array([1]), 4.8711213e-06, 0.99999511),\n",
       " (array([1]), array([1]), 2.2328234e-06, 0.99999774),\n",
       " (array([0]), array([0]), 0.99636519, 0.0036348244),\n",
       " (array([1]), array([1]), 7.9322181e-06, 0.99999201),\n",
       " (array([0]), array([0]), 0.99008149, 0.0099184969),\n",
       " (array([1]), array([1]), 8.3392355e-05, 0.99991655),\n",
       " (array([0]), array([0]), 0.95903748, 0.040962521),\n",
       " (array([1]), array([1]), 1.51354e-08, 1.0),\n",
       " (array([1]), array([1]), 2.915682e-07, 0.99999976),\n",
       " (array([1]), array([1]), 0.0001195386, 0.99988043),\n",
       " (array([1]), array([1]), 4.3561899e-06, 0.99999559),\n",
       " (array([1]), array([1]), 7.4654594e-10, 1.0)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90\n"
     ]
    }
   ],
   "source": [
    "for i in mut_to_nor:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/mul_img{}_cam.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "32\n",
      "37\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "for i in nor_to_mul:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/nor_img{}_cam.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    if test_data[i][1] == 0:\n",
    "        img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "        img_save_data_path = './img/mul_img{}.nii'.format(i)\n",
    "        nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make input tensor require gradient\n",
    "    X.requires_grad_()\n",
    "    ##############################################################################\n",
    "    # Perform a forward and backward pass through the model to compute the gradient \n",
    "    # of the correct class score with respect to each input image. You first want \n",
    "    # to compute the loss over the correct scores (we'll combine losses across a batch\n",
    "    # by summing), and then compute the gradients with a backward pass.\n",
    "    ##############################################################################\n",
    "    scores = model(X)\n",
    "    \n",
    "    # Get the correct class computed scores.\n",
    "    scores = scores.gather(1, y.view(-1, 1)).squeeze()  \n",
    "    \n",
    "    # Backward pass, need to supply initial gradients of same tensor shape as scores.\n",
    "    scores.backward(torch.tensor(10.0).cuda(device))\n",
    "    \n",
    "    # Get gradient for image.\n",
    "    saliency = X.grad.data\n",
    "    \n",
    "    # Convert from 3d to 1d.\n",
    "    saliency = saliency.abs()\n",
    "    saliency = saliency.squeeze()\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    saliency = compute_saliency_maps(inputs, labels, net)\n",
    "    \n",
    "    max_value = torch.max(saliency)\n",
    "    saliency[saliency >= (max_value*0.2)] = 1\n",
    "    saliency[saliency < (max_value*0.2)] = 0\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.cpu().detach().numpy()+0.5),np.eye(4))\n",
    "    img_save_data_path = './saliency_map/img_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency.cpu().numpy()),np.eye(4))\n",
    "    saliency_save_data_path = './saliency_map/salency_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(saliency).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = torch.max(saliency)\n",
    "saliency[saliency >= (max_value*0.2)] = 1\n",
    "saliency[saliency < (max_value*0.2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 96])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# net.fc1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "can't use starred expression here (cell_name, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"cell_name\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m can't use starred expression here\n"
     ]
    }
   ],
   "source": [
    "# outputs= []\n",
    "# def hook(module, input, output):\n",
    "#     outputs.append(output)\n",
    "\n",
    "# net.conv8_bn.register_forward_hook(hook)\n",
    "# out = net(res)\n",
    "# out = net(res1)\n",
    "# print(outputs)\n",
    "\n",
    "\n",
    "# test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "# test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "# for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "#     inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "#     inputs = inputs.to(device)\n",
    "#     labels = labels.to(device)\n",
    "#     saliency = compute_saliency_maps(inputs, labels, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cpu()\n",
    "net.eval()\n",
    "\n",
    "fc_weight = net.fc1.weight.data\n",
    "\n",
    "res50_conv = nn.Sequential(*list(net.children())[:-3])\n",
    "for param in res50_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    saliency = compute_cam_maps(inputs, labels, net, fc_weight, res50_conv)\n",
    "    \n",
    "#     max_value = np.max(saliency)\n",
    "#     saliency[saliency >= (max_value*0.2)] = 1\n",
    "#     saliency[saliency < (max_value*0.2)] = 0\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.numpy()+0.5),np.eye(4))\n",
    "    img_save_data_path = './cam_map/img_label{}_{}.nii'.format(labels.numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency),np.eye(4))\n",
    "    saliency_save_data_path = './cam_map/salency_label{}_{}.nii'.format(labels.numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213477.34"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam represent class saliency map\n",
    "def compute_cam_maps(X, y, model, fc_weight, feature_extract): \n",
    "    model.eval()\n",
    "    \n",
    "    outputs = feature_extract(X).squeeze()\n",
    "    channels = outputs.shape[0]\n",
    "    saliency = outputs[0,...] * fc_weight[y, 0]\n",
    "    for i in range(1,channels):\n",
    "        saliency += outputs[i,...] * fc_weight[y, i]\n",
    "    saliency = zoom(saliency.numpy(), 8)\n",
    "    \n",
    "    saliency = saliency - np.min(saliency)\n",
    "    saliency = saliency / np.max(saliency)\n",
    "    \n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,96):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n",
      "torch.Size([1, 96, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "net.cpu()\n",
    "net.eval()\n",
    "\n",
    "fc_weight = net.fc1.weight.data\n",
    "\n",
    "res50_conv = nn.Sequential(*list(net.children())[:-2])\n",
    "for param in res50_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']\n",
    "    print(res50_conv(inputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
