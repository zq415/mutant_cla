{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torch\n",
    "\n",
    "from mutant_cla_network import VGG_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def read_mutant_txt(path):\n",
    "    name_list = []\n",
    "    fo = open(path)\n",
    "    for line in fo:\n",
    "        striped_line = line.strip('\\n')\n",
    "        if striped_line != '':\n",
    "            name_list.append(striped_line)\n",
    "    return name_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_names = read_mutant_txt('mutant_imgs.txt')\n",
    "data_base_path = '/scratch/zq415/grammar_cor/mutant_detect/data'\n",
    "data_folder_list = ['20180419_newdata_nii_with_filtered', 'new_data_20180522_nii', 'organized_data_nii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'All_data_112_64_64.pickle'\n",
    "with open(os.path.join(os.getcwd(),'data',save_name), \"rb\") as input_file:\n",
    "    all_train_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ['20170207_En1_E13_E3_Mut', '20170207_En1_E13_E3c_Mut', '20170207_En1_E13_E3d_Mut', '20161206_En1_E13_E3a', '20161206_En1_E13_E3b', '20161206_En1_E13_E3c', '20161206_En1_E13_E3d', '20180131_En1_E12_E5a_Mut', '20180131_En1_E12_E5b', '20180131_En1_E12_E5c_Mut', '20180202_En1_E14_E3a_Mut', '20180202_En1_E14_E3b_Mut', '20171211_En1_E10_E1a', '20170619_En1_E12_E3a', '20170706_En1_E13_E11a_Mut_reg', '20171009_En1_E12_E10a', '20171211_En1_E13_E5a_Mut_Ext', '20180201_En1_M2_E13_E4a']\n"
     ]
    }
   ],
   "source": [
    "mutant_group = [(9,10), (12,13,14), (16,17,18,19), (36,37), (38,39), (42,43), (44,45,46,47), (48,49,50,51), (52,53), (54,55),\n",
    "(56,57,58), (59,60,61), (63,64), (66,67,68), (69,70,71), (73,74), (75,76), (77,78,79), (80,81,82,83,84,85,86,87),\n",
    "(89,90), (91,92), (93,94), (95,96,97), (98,99), (100,101,102)]\n",
    "\n",
    "group_list = []\n",
    "for one_group in mutant_group:\n",
    "    for ii in range(len(one_group)):\n",
    "        group_list.append(one_group[ii])\n",
    "single_mutant = [i for i in range(len(mutant_names)) if i not in group_list]\n",
    "\n",
    "test_mut_names = []\n",
    "for i in range(1,len(mutant_group),6):\n",
    "    for ii in range(len(mutant_group[i])):\n",
    "        test_mut_names.append(mutant_names[mutant_group[i][ii]])\n",
    "\n",
    "for i in range(1,len(single_mutant),6):\n",
    "    test_mut_names.append(mutant_names[single_mutant[i]])\n",
    "    \n",
    "print(len(test_mut_names),test_mut_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "471\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] in mutant_names:\n",
    "        if all_train_data[i][2] in test_mut_names:\n",
    "            test_data.append((all_train_data[i][3]-0.5, 0))\n",
    "        else:\n",
    "            train_data.append((all_train_data[i][3]-0.5,0))\n",
    "    else:\n",
    "        random.seed(i*8)\n",
    "        if random.uniform(0,1) < 0.16:\n",
    "            test_data.append((all_train_data[i][3]-0.5,1))\n",
    "        else:\n",
    "            train_data.append((all_train_data[i][3]-0.5,1))\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Mouse_sub_volumes(Dataset):\n",
    "    \"\"\"Mouse sub-volumes BV dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, all_data , transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            all_whole_volumes: Contain all the padded whole BV volumes as a dic\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.all_data = all_data\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self, num):\n",
    "        \n",
    "        current_img, label = self.all_data[num]\n",
    "        \n",
    "        img = np.float32(current_img[np.newaxis,...])\n",
    "        sample = {'image': img, 'label': label}\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Flip the image for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,ori_probability=0.20):\n",
    "        self.ori_probability = ori_probability\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['image'], sample['label']\n",
    "            random_choise1=random.choice([1,2,3,4,5,6,7,8])\n",
    "            img[0,...] = {1: lambda x: x,\n",
    "                          2: lambda x: x[::-1,:,:],\n",
    "                          3: lambda x: x[:,::-1,:],\n",
    "                          4: lambda x: x[:,:,::-1],\n",
    "                          5: lambda x: x[::-1,::-1,:],\n",
    "                          6: lambda x: x[::-1,:,::-1],\n",
    "                          7: lambda x: x[:,::-1,::-1],\n",
    "                          8: lambda x: x[::-1,::-1,::-1]\n",
    "                          }[random_choise1](img[0,...])\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "# import torch\n",
    "\n",
    "# class VGG_net(nn.Module):\n",
    "#     def __init__(self,conv_drop_rate=0.10,linear_drop_rate=0.10):\n",
    "#         super(VGG_net, self).__init__()\n",
    "#         self.conv1 = nn.Conv3d(in_channels=1, out_channels=12, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "#         self.conv1_bn = nn.BatchNorm3d(12)\n",
    "#         self.conv2 = nn.Conv3d(in_channels=12, out_channels=12, kernel_size=3,stride=1,padding=2, dilation=2)\n",
    "#         self.conv2_bn = nn.BatchNorm3d(12)\n",
    "#         self.pool1 = nn.MaxPool3d(2, 2)\n",
    "#         self.dropout1 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "#         self.conv3 = nn.Conv3d(in_channels=12, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "#         self.conv3_bn = nn.BatchNorm3d(24)\n",
    "#         self.conv4 = nn.Conv3d(in_channels=24, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "#         self.conv4_bn = nn.BatchNorm3d(24)\n",
    "#         self.pool2 = nn.MaxPool3d(2, 2)\n",
    "#         self.dropout2 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "#         self.conv5 = nn.Conv3d(in_channels=24, out_channels=48, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "#         self.conv5_bn = nn.BatchNorm3d(48)\n",
    "#         self.conv6 = nn.Conv3d(in_channels=48, out_channels=48, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "#         self.conv6_bn = nn.BatchNorm3d(48)\n",
    "#         self.pool3 = nn.MaxPool3d(2, 2)\n",
    "#         self.dropout3 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "#         self.conv7 = nn.Conv3d(in_channels=48, out_channels=72, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "#         self.conv7_bn = nn.BatchNorm3d(72)\n",
    "#         self.conv8 = nn.Conv3d(in_channels=72, out_channels=72, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "#         self.conv8_bn = nn.BatchNorm3d(72)\n",
    "#         self.pool4 = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "#         self.dropout4 = nn.Dropout3d(conv_drop_rate)\n",
    "#         self.pool5 = nn.AdaptiveMaxPool3d((1,1,1))\n",
    "#         self.dropout5 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        \n",
    "#         self.fc1 = nn.Linear(144, 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1_bn(F.relu(self.conv1(x)))\n",
    "#         x = self.dropout1(self.pool1(self.conv2_bn(F.relu(self.conv2(x)))))\n",
    "        \n",
    "#         x = self.conv3_bn(F.relu(self.conv3(x)))\n",
    "#         x = self.dropout2(self.pool2(self.conv4_bn(F.relu(self.conv4(x)))))\n",
    "        \n",
    "#         x = self.conv5_bn(F.relu(self.conv5(x)))\n",
    "#         x = self.dropout3(self.pool3(self.conv6_bn(F.relu(self.conv6(x)))))\n",
    "        \n",
    "#         x = self.conv7_bn(F.relu(self.conv7(x)))\n",
    "#         x = self.conv8_bn(F.relu(self.conv8(x)))\n",
    "        \n",
    "#         x1 = self.dropout4(self.pool4(x))\n",
    "#         x2 = self.dropout5(self.pool5(x))\n",
    "        \n",
    "#         x1 = x1.view(-1, 72)\n",
    "#         x2 = x2.view(-1, 72)\n",
    "#         x = torch.cat((x1, x2), 1)\n",
    "#         #x = self.dropout5(self.fc1_bn(F.relu(self.fc1(x))))\n",
    "#         x = self.fc1(x)\n",
    "#         return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        i_batch += 1\n",
    "        if i_batch % 10 == 0:\n",
    "            print(\"epoch {}, batch {}, current loss {}\".format(epoch+1,i_batch,running_loss/10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy()))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels\n",
    "\n",
    "def get_confusion_matrix(true_predicted_labels):\n",
    "    cross_table = np.zeros([2,2])\n",
    "    mut_to_nor = []\n",
    "    nor_to_mul = []\n",
    "    test_dic = true_predicted_labels\n",
    "    for i in range(len(test_dic)):\n",
    "        if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "            cross_table[0,0] += 1\n",
    "        elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "            cross_table[0,1] += 1\n",
    "            mut_to_nor.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "            cross_table[1,0] += 1\n",
    "            nor_to_mul.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "            cross_table[1,1] += 1\n",
    "    print(cross_table)\n",
    "    print(mut_to_nor)\n",
    "    print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 355358 parameters in the model\n",
      "choose SGD as optimizer\n",
      "epoch 1, batch 10, current loss 1.858144462108612\n",
      "epoch 1, batch 20, current loss 1.6685553729534148\n",
      "epoch 1, batch 30, current loss 0.8525050461292267\n",
      "epoch 2, batch 10, current loss 0.9466915488243103\n",
      "epoch 2, batch 20, current loss 1.2554169461131095\n",
      "epoch 2, batch 30, current loss 2.5280625224113464\n",
      "epoch 3, batch 10, current loss 1.7856557548046113\n",
      "epoch 3, batch 20, current loss 1.723900133371353\n",
      "epoch 3, batch 30, current loss 1.3091862618923187\n",
      "epoch 4, batch 10, current loss 0.7452906399965287\n",
      "epoch 4, batch 20, current loss 0.7101096510887146\n",
      "epoch 4, batch 30, current loss 0.7218316495418549\n",
      "epoch 5, batch 10, current loss 0.6564859122037887\n",
      "epoch 5, batch 20, current loss 0.7639168262481689\n",
      "epoch 5, batch 30, current loss 0.6761782944202424\n",
      "epoch 6, batch 10, current loss 0.6696746617555618\n",
      "epoch 6, batch 20, current loss 0.6851435273885726\n",
      "epoch 6, batch 30, current loss 0.8221352756023407\n",
      "epoch 7, batch 10, current loss 0.7120396554470062\n",
      "epoch 7, batch 20, current loss 0.7578784644603729\n",
      "epoch 7, batch 30, current loss 0.6738012433052063\n",
      "epoch 8, batch 10, current loss 0.7311197072267532\n",
      "epoch 8, batch 20, current loss 0.6774612218141556\n",
      "epoch 8, batch 30, current loss 0.7042493939399719\n",
      "epoch 9, batch 10, current loss 0.7648283183574677\n",
      "epoch 9, batch 20, current loss 0.7289294719696044\n",
      "epoch 9, batch 30, current loss 0.7165420591831207\n",
      "epoch 10, batch 10, current loss 0.6425546139478684\n",
      "epoch 10, batch 20, current loss 0.6746923089027405\n",
      "epoch 10, batch 30, current loss 0.7077125996351242\n",
      "epoch 10 train accuracy: \n",
      "total_num:471, test accuracy:0.8174097664543525, positive_acc:1.0, negative_acc:0.0\n",
      "[[   0.   86.]\n",
      " [   0.  385.]]\n",
      "[2, 20, 39, 41, 65, 72, 73, 74, 76, 83, 85, 100, 110, 114, 124, 152, 153, 154, 155, 157, 168, 177, 180, 190, 191, 193, 198, 210, 212, 213, 214, 215, 223, 243, 246, 247, 252, 256, 257, 258, 259, 263, 266, 282, 283, 285, 287, 288, 296, 300, 301, 302, 303, 304, 306, 307, 312, 313, 315, 317, 319, 330, 331, 339, 345, 348, 349, 355, 363, 366, 369, 379, 384, 396, 400, 402, 404, 415, 417, 418, 420, 430, 433, 440, 455, 458]\n",
      "[]\n",
      "-------------------\n",
      "epoch 10 test accuracy: \n",
      "total_num:96, test accuracy:0.8125, positive_acc:1.0, negative_acc:0.0\n",
      "[[  0.  18.]\n",
      " [  0.  78.]]\n",
      "[0, 9, 28, 34, 35, 36, 39, 44, 60, 61, 62, 63, 66, 74, 78, 86, 88, 90]\n",
      "[]\n",
      "epoch 11, batch 10, current loss 0.6750724077224731\n",
      "epoch 11, batch 20, current loss 0.7042151987552643\n",
      "epoch 11, batch 30, current loss 0.6689280509948731\n",
      "epoch 12, batch 10, current loss 0.6613284349441528\n",
      "epoch 12, batch 20, current loss 0.7030315697193146\n",
      "epoch 12, batch 30, current loss 0.6653670877218246\n",
      "epoch 13, batch 10, current loss 0.6317192733287811\n",
      "epoch 13, batch 20, current loss 0.6648551106452942\n",
      "epoch 13, batch 30, current loss 0.6686239123344422\n",
      "epoch 14, batch 10, current loss 0.7192375957965851\n",
      "epoch 14, batch 20, current loss 0.719845575094223\n",
      "epoch 14, batch 30, current loss 0.646909499168396\n",
      "epoch 15, batch 10, current loss 0.6691104710102082\n",
      "epoch 15, batch 20, current loss 0.6704760074615479\n",
      "epoch 15, batch 30, current loss 0.635253769159317\n",
      "epoch 16, batch 10, current loss 0.6853792607784271\n",
      "epoch 16, batch 20, current loss 0.7001803994178772\n",
      "epoch 16, batch 30, current loss 0.6467100560665131\n",
      "epoch 17, batch 10, current loss 0.6747637450695038\n",
      "epoch 17, batch 20, current loss 0.6314437508583068\n",
      "epoch 17, batch 30, current loss 0.7060547441244125\n",
      "epoch 18, batch 10, current loss 0.6561957478523255\n",
      "epoch 18, batch 20, current loss 0.6700256586074829\n",
      "epoch 18, batch 30, current loss 0.6274385809898376\n",
      "epoch 19, batch 10, current loss 0.6920688629150391\n",
      "epoch 19, batch 20, current loss 0.6596171677112579\n",
      "epoch 19, batch 30, current loss 0.643478125333786\n",
      "epoch 20, batch 10, current loss 0.7101612895727157\n",
      "epoch 20, batch 20, current loss 0.630010974407196\n",
      "epoch 20, batch 30, current loss 0.6377300798892975\n",
      "epoch 20 train accuracy: \n",
      "total_num:471, test accuracy:0.881104033970276, positive_acc:0.9766233766233766, negative_acc:0.45348837209302323\n",
      "[[  39.   47.]\n",
      " [   9.  376.]]\n",
      "[2, 20, 39, 41, 65, 72, 73, 74, 83, 85, 100, 124, 154, 155, 177, 180, 190, 191, 193, 210, 212, 213, 214, 215, 243, 259, 263, 266, 282, 287, 288, 300, 301, 302, 303, 304, 306, 312, 313, 319, 348, 349, 400, 402, 404, 420, 440]\n",
      "[64, 101, 143, 151, 184, 195, 248, 357, 374]\n",
      "-------------------\n",
      "epoch 20 test accuracy: \n",
      "total_num:96, test accuracy:0.8229166666666666, positive_acc:0.9743589743589743, negative_acc:0.16666666666666666\n",
      "[[  3.  15.]\n",
      " [  2.  76.]]\n",
      "[9, 28, 34, 35, 36, 44, 60, 61, 62, 63, 66, 74, 86, 88, 90]\n",
      "[32, 93]\n",
      "epoch 21, batch 10, current loss 0.6549124360084534\n",
      "epoch 21, batch 20, current loss 0.606088039278984\n",
      "epoch 21, batch 30, current loss 0.5177370131015777\n",
      "epoch 22, batch 10, current loss 0.6617804914712906\n",
      "epoch 22, batch 20, current loss 0.6136502027511597\n",
      "epoch 22, batch 30, current loss 0.4604158908128738\n",
      "epoch 23, batch 10, current loss 0.7341596633195877\n",
      "epoch 23, batch 20, current loss 0.5757952779531479\n",
      "epoch 23, batch 30, current loss 0.5571546971797943\n",
      "epoch 24, batch 10, current loss 0.41700870990753175\n",
      "epoch 24, batch 20, current loss 0.4289806842803955\n",
      "epoch 24, batch 30, current loss 0.5893375992774963\n",
      "epoch 25, batch 10, current loss 0.42318267524242403\n",
      "epoch 25, batch 20, current loss 0.40756562501192095\n",
      "epoch 25, batch 30, current loss 0.31903122514486315\n",
      "epoch 26, batch 10, current loss 0.2743567615747452\n",
      "epoch 26, batch 20, current loss 0.446760305762291\n",
      "epoch 26, batch 30, current loss 0.32199686393141747\n",
      "epoch 27, batch 10, current loss 0.3647281289100647\n",
      "epoch 27, batch 20, current loss 0.3687406271696091\n",
      "epoch 27, batch 30, current loss 0.43466041758656504\n",
      "epoch 28, batch 10, current loss 0.39406231939792635\n",
      "epoch 28, batch 20, current loss 0.4387541517615318\n",
      "epoch 28, batch 30, current loss 0.389343748986721\n",
      "epoch 29, batch 10, current loss 0.21734148859977723\n",
      "epoch 29, batch 20, current loss 0.1909261591732502\n",
      "epoch 29, batch 30, current loss 0.3255848839879036\n",
      "epoch 30, batch 10, current loss 0.2993084229528904\n",
      "epoch 30, batch 20, current loss 0.29811001792550085\n",
      "epoch 30, batch 30, current loss 0.40877389833331107\n",
      "epoch 30 train accuracy: \n",
      "total_num:471, test accuracy:0.9575371549893843, positive_acc:0.987012987012987, negative_acc:0.8255813953488372\n",
      "[[  71.   15.]\n",
      " [   5.  380.]]\n",
      "[65, 72, 76, 177, 180, 190, 193, 198, 243, 266, 287, 313, 319, 379, 420]\n",
      "[80, 192, 195, 371, 454]\n",
      "-------------------\n",
      "epoch 30 test accuracy: \n",
      "total_num:96, test accuracy:0.9270833333333334, positive_acc:0.9743589743589743, negative_acc:0.7222222222222222\n",
      "[[ 13.   5.]\n",
      " [  2.  76.]]\n",
      "[0, 9, 35, 88, 90]\n",
      "[32, 57]\n",
      "epoch 31, batch 10, current loss 0.1913355953991413\n",
      "epoch 31, batch 20, current loss 0.33749975748360156\n",
      "epoch 31, batch 30, current loss 0.2896838396787643\n",
      "epoch 32, batch 10, current loss 0.37058529183268546\n",
      "epoch 32, batch 20, current loss 0.3568500392138958\n",
      "epoch 32, batch 30, current loss 0.32429220974445344\n",
      "epoch 33, batch 10, current loss 0.2652540190145373\n",
      "epoch 33, batch 20, current loss 0.2934751374647021\n",
      "epoch 33, batch 30, current loss 0.288446541223675\n",
      "epoch 34, batch 10, current loss 0.18410171642899514\n",
      "epoch 34, batch 20, current loss 0.19580897316336632\n",
      "epoch 34, batch 30, current loss 0.27508884146809576\n",
      "epoch 35, batch 10, current loss 0.25352318231016396\n",
      "epoch 35, batch 20, current loss 0.18230291716754438\n",
      "epoch 35, batch 30, current loss 0.21470044925808907\n",
      "epoch 36, batch 10, current loss 0.3499106429517269\n",
      "epoch 36, batch 20, current loss 0.19365831092000008\n",
      "epoch 36, batch 30, current loss 0.2391050435602665\n",
      "epoch 37, batch 10, current loss 0.15374881625175477\n",
      "epoch 37, batch 20, current loss 0.20409893039613963\n",
      "epoch 37, batch 30, current loss 0.39866003636270764\n",
      "epoch 38, batch 10, current loss 0.39067149013280866\n",
      "epoch 38, batch 20, current loss 0.2634111396968365\n",
      "epoch 38, batch 30, current loss 0.25644801184535027\n",
      "epoch 39, batch 10, current loss 0.3226324826478958\n",
      "epoch 39, batch 20, current loss 0.1440412987023592\n",
      "epoch 39, batch 30, current loss 0.20064356476068496\n",
      "epoch 40, batch 10, current loss 0.1931780580431223\n",
      "epoch 40, batch 20, current loss 0.07202004441060125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40, batch 30, current loss 0.22350907064974307\n",
      "epoch 40 train accuracy: \n",
      "total_num:471, test accuracy:0.9639065817409767, positive_acc:0.961038961038961, negative_acc:0.9767441860465116\n",
      "[[  84.    2.]\n",
      " [  15.  370.]]\n",
      "[190, 193]\n",
      "[18, 80, 101, 135, 163, 184, 195, 202, 318, 352, 357, 374, 410, 454, 462]\n",
      "-------------------\n",
      "epoch 40 test accuracy: \n",
      "total_num:96, test accuracy:0.9270833333333334, positive_acc:0.9358974358974359, negative_acc:0.8888888888888888\n",
      "[[ 16.   2.]\n",
      " [  5.  73.]]\n",
      "[0, 9]\n",
      "[16, 32, 37, 38, 80]\n",
      "epoch 41, batch 10, current loss 0.141284741461277\n",
      "epoch 41, batch 20, current loss 0.16485922001302242\n",
      "epoch 41, batch 30, current loss 0.22170539004728199\n",
      "epoch 42, batch 10, current loss 0.32020637318491935\n",
      "epoch 42, batch 20, current loss 0.23655359596014022\n",
      "epoch 42, batch 30, current loss 0.19551819935441017\n",
      "epoch 43, batch 10, current loss 0.16569985868409276\n",
      "epoch 43, batch 20, current loss 0.26112307570874693\n",
      "epoch 43, batch 30, current loss 0.28252691477537156\n",
      "epoch 44, batch 10, current loss 0.12760977782309055\n",
      "epoch 44, batch 20, current loss 0.22181884720921516\n",
      "epoch 44, batch 30, current loss 0.31664192453026774\n",
      "epoch 45, batch 10, current loss 0.1214251009747386\n",
      "epoch 45, batch 20, current loss 0.21483472287654876\n",
      "epoch 45, batch 30, current loss 0.1913014579564333\n",
      "epoch 46, batch 10, current loss 0.15479244654998184\n",
      "epoch 46, batch 20, current loss 0.16133624762296678\n",
      "epoch 46, batch 30, current loss 0.10786462109535933\n",
      "epoch 47, batch 10, current loss 0.11593261249363422\n",
      "epoch 47, batch 20, current loss 0.07336493427865207\n",
      "epoch 47, batch 30, current loss 0.24607933266088367\n",
      "epoch 48, batch 10, current loss 0.15049221701920032\n",
      "epoch 48, batch 20, current loss 0.1606967531144619\n",
      "epoch 48, batch 30, current loss 0.22371446155011654\n",
      "epoch 49, batch 10, current loss 0.14262211434543132\n",
      "epoch 49, batch 20, current loss 0.12247453406453132\n",
      "epoch 49, batch 30, current loss 0.1132427977398038\n",
      "epoch 50, batch 10, current loss 0.11979483179748059\n",
      "epoch 50, batch 20, current loss 0.22049246933311223\n",
      "epoch 50, batch 30, current loss 0.15113155208528042\n",
      "epoch 50 train accuracy: \n",
      "total_num:471, test accuracy:0.9469214437367304, positive_acc:0.9376623376623376, negative_acc:0.9883720930232558\n",
      "[[  85.    1.]\n",
      " [  24.  361.]]\n",
      "[72]\n",
      "[5, 12, 32, 62, 75, 80, 135, 138, 140, 141, 143, 149, 163, 178, 184, 192, 194, 202, 305, 321, 357, 374, 410, 454]\n",
      "-------------------\n",
      "epoch 50 test accuracy: \n",
      "total_num:96, test accuracy:0.875, positive_acc:0.8589743589743589, negative_acc:0.9444444444444444\n",
      "[[ 17.   1.]\n",
      " [ 11.  67.]]\n",
      "[9]\n",
      "[16, 31, 32, 37, 38, 40, 46, 57, 67, 73, 80]\n",
      "epoch 51, batch 10, current loss 0.16780790500342846\n",
      "epoch 51, batch 20, current loss 0.12248125076293945\n",
      "epoch 51, batch 30, current loss 0.1776481680572033\n",
      "epoch 52, batch 10, current loss 0.19773852378129958\n",
      "epoch 52, batch 20, current loss 0.08137011826038361\n",
      "epoch 52, batch 30, current loss 0.13894222285598518\n",
      "epoch 53, batch 10, current loss 0.07119359094649554\n",
      "epoch 53, batch 20, current loss 0.06309393579140306\n",
      "epoch 53, batch 30, current loss 0.19884116370230914\n",
      "epoch 54, batch 10, current loss 0.12743503376841545\n",
      "epoch 54, batch 20, current loss 0.1686844626441598\n",
      "epoch 54, batch 30, current loss 0.12009424762800336\n",
      "epoch 55, batch 10, current loss 0.17430826127529145\n",
      "epoch 55, batch 20, current loss 0.10989341381937265\n",
      "epoch 55, batch 30, current loss 0.07978755470830948\n",
      "epoch 56, batch 10, current loss 0.04336912431754172\n",
      "epoch 56, batch 20, current loss 0.06162517140619457\n",
      "epoch 56, batch 30, current loss 0.296329864859581\n",
      "epoch 57, batch 10, current loss 0.09770985152572394\n",
      "epoch 57, batch 20, current loss 0.0774454657919705\n",
      "epoch 57, batch 30, current loss 0.14880504622124135\n",
      "epoch 58, batch 10, current loss 0.13834299594163896\n",
      "epoch 58, batch 20, current loss 0.060311405919492245\n",
      "epoch 58, batch 30, current loss 0.09875046745873987\n",
      "epoch 59, batch 10, current loss 0.1043675442924723\n",
      "epoch 59, batch 20, current loss 0.2037827863357961\n",
      "epoch 59, batch 30, current loss 0.14724552929401397\n",
      "epoch 60, batch 10, current loss 0.09497550241649151\n",
      "epoch 60, batch 20, current loss 0.16246099402196706\n",
      "epoch 60, batch 30, current loss 0.1004636012017727\n",
      "epoch 60 train accuracy: \n",
      "total_num:471, test accuracy:0.9575371549893843, positive_acc:0.948051948051948, negative_acc:1.0\n",
      "[[  86.    0.]\n",
      " [  20.  365.]]\n",
      "[]\n",
      "[18, 28, 50, 80, 101, 143, 163, 184, 195, 202, 220, 321, 352, 357, 371, 374, 390, 410, 454, 462]\n",
      "-------------------\n",
      "epoch 60 test accuracy: \n",
      "total_num:96, test accuracy:0.9479166666666666, positive_acc:0.9487179487179487, negative_acc:0.9444444444444444\n",
      "[[ 17.   1.]\n",
      " [  4.  74.]]\n",
      "[0]\n",
      "[32, 37, 38, 57]\n",
      "epoch 61, batch 10, current loss 0.13258130215108394\n",
      "epoch 61, batch 20, current loss 0.1123193722218275\n",
      "epoch 61, batch 30, current loss 0.05800561364740133\n",
      "epoch 62, batch 10, current loss 0.06766045656986534\n",
      "epoch 62, batch 20, current loss 0.09546474982053041\n",
      "epoch 62, batch 30, current loss 0.12548281103372574\n",
      "epoch 63, batch 10, current loss 0.1164590639877133\n",
      "epoch 63, batch 20, current loss 0.1287055227905512\n",
      "epoch 63, batch 30, current loss 0.12918608486652375\n",
      "epoch 64, batch 10, current loss 0.08040822562761604\n",
      "epoch 64, batch 20, current loss 0.19094252621289343\n",
      "epoch 64, batch 30, current loss 0.04741022945381701\n",
      "epoch 65, batch 10, current loss 0.1677661519497633\n",
      "epoch 65, batch 20, current loss 0.05573336244560778\n",
      "epoch 65, batch 30, current loss 0.07817106153815985\n",
      "epoch 66, batch 10, current loss 0.09394476902671159\n",
      "epoch 66, batch 20, current loss 0.07612615558318794\n",
      "epoch 66, batch 30, current loss 0.054195536673069\n",
      "epoch 67, batch 10, current loss 0.11411785166710615\n",
      "epoch 67, batch 20, current loss 0.1254072619602084\n",
      "epoch 67, batch 30, current loss 0.15783728212118148\n",
      "epoch 68, batch 10, current loss 0.12085658013820648\n",
      "epoch 68, batch 20, current loss 0.09122477602213622\n",
      "epoch 68, batch 30, current loss 0.04134978288784623\n",
      "epoch 69, batch 10, current loss 0.1468766621313989\n",
      "epoch 69, batch 20, current loss 0.08047713337000459\n",
      "epoch 69, batch 30, current loss 0.09471859876066446\n",
      "epoch 70, batch 10, current loss 0.10381768709048629\n",
      "epoch 70, batch 20, current loss 0.06574158319272101\n",
      "epoch 70, batch 30, current loss 0.2269480279646814\n",
      "epoch 70 train accuracy: \n",
      "total_num:471, test accuracy:0.9915074309978769, positive_acc:0.9896103896103896, negative_acc:1.0\n",
      "[[  86.    0.]\n",
      " [   4.  381.]]\n",
      "[]\n",
      "[80, 202, 321, 454]\n",
      "-------------------\n",
      "epoch 70 test accuracy: \n",
      "total_num:96, test accuracy:0.9479166666666666, positive_acc:0.9615384615384616, negative_acc:0.8888888888888888\n",
      "[[ 16.   2.]\n",
      " [  3.  75.]]\n",
      "[0, 9]\n",
      "[32, 38, 57]\n",
      "epoch 71, batch 10, current loss 0.057378252036869526\n",
      "epoch 71, batch 20, current loss 0.1509876050055027\n",
      "epoch 71, batch 30, current loss 0.04103152733296156\n",
      "epoch 72, batch 10, current loss 0.04998568487353623\n",
      "epoch 72, batch 20, current loss 0.1405152915045619\n",
      "epoch 72, batch 30, current loss 0.10089374249801039\n",
      "epoch 73, batch 10, current loss 0.10237035979516804\n",
      "epoch 73, batch 20, current loss 0.1238549305126071\n",
      "epoch 73, batch 30, current loss 0.11943086062092334\n",
      "epoch 74, batch 10, current loss 0.10493901409208775\n",
      "epoch 74, batch 20, current loss 0.0803252493031323\n",
      "epoch 74, batch 30, current loss 0.13808131930418313\n",
      "epoch 75, batch 10, current loss 0.07516775662079453\n",
      "epoch 75, batch 20, current loss 0.13808057704009116\n",
      "epoch 75, batch 30, current loss 0.12858792543411254\n",
      "epoch 76, batch 10, current loss 0.07132269362919033\n",
      "epoch 76, batch 20, current loss 0.034659359883517024\n",
      "epoch 76, batch 30, current loss 0.16618974274024367\n",
      "epoch 77, batch 10, current loss 0.051334810769185425\n",
      "epoch 77, batch 20, current loss 0.03764960346743464\n",
      "epoch 77, batch 30, current loss 0.056074477499350905\n",
      "epoch 78, batch 10, current loss 0.12701888103038073\n",
      "epoch 78, batch 20, current loss 0.061537970695644616\n",
      "epoch 78, batch 30, current loss 0.1470039422158152\n",
      "epoch 79, batch 10, current loss 0.061720912368036805\n",
      "epoch 79, batch 20, current loss 0.054178296215832235\n",
      "epoch 79, batch 30, current loss 0.11373645965941251\n",
      "epoch 80, batch 10, current loss 0.1711529029533267\n",
      "epoch 80, batch 20, current loss 0.0583374734967947\n",
      "epoch 80, batch 30, current loss 0.18951648930087686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80 train accuracy: \n",
      "total_num:471, test accuracy:0.9766454352441614, positive_acc:0.9714285714285714, negative_acc:1.0\n",
      "[[  86.    0.]\n",
      " [  11.  374.]]\n",
      "[]\n",
      "[80, 101, 135, 143, 163, 194, 202, 305, 374, 410, 454]\n",
      "-------------------\n",
      "epoch 80 test accuracy: \n",
      "total_num:96, test accuracy:0.90625, positive_acc:0.8974358974358975, negative_acc:0.9444444444444444\n",
      "[[ 17.   1.]\n",
      " [  8.  70.]]\n",
      "[9]\n",
      "[16, 32, 37, 38, 40, 46, 57, 80]\n",
      "epoch 81, batch 10, current loss 0.030474188551306725\n",
      "epoch 81, batch 20, current loss 0.1036498675122857\n",
      "epoch 81, batch 30, current loss 0.09762085913680493\n",
      "epoch 82, batch 10, current loss 0.07364280540496111\n",
      "epoch 82, batch 20, current loss 0.03392616244964301\n",
      "epoch 82, batch 30, current loss 0.08086371403187513\n",
      "epoch 83, batch 10, current loss 0.15035148514434696\n",
      "epoch 83, batch 20, current loss 0.11113802534528076\n",
      "epoch 83, batch 30, current loss 0.09156572362408041\n",
      "epoch 84, batch 10, current loss 0.12296034549362958\n",
      "epoch 84, batch 20, current loss 0.09637522930279374\n",
      "epoch 84, batch 30, current loss 0.10103206902276725\n",
      "epoch 85, batch 10, current loss 0.10222678449936211\n",
      "epoch 85, batch 20, current loss 0.027777656842954458\n",
      "epoch 85, batch 30, current loss 0.04208896984346211\n",
      "epoch 86, batch 10, current loss 0.06296585283707827\n",
      "epoch 86, batch 20, current loss 0.07983849816955627\n",
      "epoch 86, batch 30, current loss 0.14339681747369468\n",
      "epoch 87, batch 10, current loss 0.14343242328613998\n",
      "epoch 87, batch 20, current loss 0.11113676908425987\n",
      "epoch 87, batch 30, current loss 0.08010637247934937\n",
      "epoch 88, batch 10, current loss 0.10727832152042538\n",
      "epoch 88, batch 20, current loss 0.05264312643557787\n",
      "epoch 88, batch 30, current loss 0.054555009305477145\n",
      "epoch 89, batch 10, current loss 0.05997042376548052\n",
      "epoch 89, batch 20, current loss 0.0349748867098242\n",
      "epoch 89, batch 30, current loss 0.06246150427032262\n",
      "epoch 90, batch 10, current loss 0.06782452836632728\n",
      "epoch 90, batch 20, current loss 0.06912175239995122\n",
      "epoch 90, batch 30, current loss 0.05508610708639026\n",
      "epoch 90 train accuracy: \n",
      "total_num:471, test accuracy:0.9872611464968153, positive_acc:0.9844155844155844, negative_acc:1.0\n",
      "[[  86.    0.]\n",
      " [   6.  379.]]\n",
      "[]\n",
      "[80, 141, 163, 202, 374, 454]\n",
      "-------------------\n",
      "epoch 90 test accuracy: \n",
      "total_num:96, test accuracy:0.9270833333333334, positive_acc:0.9358974358974359, negative_acc:0.8888888888888888\n",
      "[[ 16.   2.]\n",
      " [  5.  73.]]\n",
      "[0, 9]\n",
      "[32, 38, 46, 57, 80]\n",
      "epoch 91, batch 10, current loss 0.12079752376303077\n",
      "epoch 91, batch 20, current loss 0.04101461567915976\n",
      "epoch 91, batch 30, current loss 0.09532524701207876\n",
      "epoch 92, batch 10, current loss 0.10445163799449801\n",
      "epoch 92, batch 20, current loss 0.1060704861069098\n",
      "epoch 92, batch 30, current loss 0.11312588504515589\n",
      "epoch 93, batch 10, current loss 0.09170608229469508\n",
      "epoch 93, batch 20, current loss 0.11902786302380264\n",
      "epoch 93, batch 30, current loss 0.04200330357998609\n",
      "epoch 94, batch 10, current loss 0.061173378099920225\n",
      "epoch 94, batch 20, current loss 0.10838044880656525\n",
      "epoch 94, batch 30, current loss 0.18571516426454765\n",
      "epoch 95, batch 10, current loss 0.18993094156030566\n",
      "epoch 95, batch 20, current loss 0.06053583731409162\n",
      "epoch 95, batch 30, current loss 0.1600812166929245\n",
      "epoch 96, batch 10, current loss 0.06343499589711428\n",
      "epoch 96, batch 20, current loss 0.11584317164961248\n",
      "epoch 96, batch 30, current loss 0.0434304503723979\n",
      "epoch 97, batch 10, current loss 0.04956129528582096\n",
      "epoch 97, batch 20, current loss 0.13751035155728458\n",
      "epoch 97, batch 30, current loss 0.08249376870226115\n",
      "epoch 98, batch 10, current loss 0.10605211229994893\n",
      "epoch 98, batch 20, current loss 0.19559296988882124\n",
      "epoch 98, batch 30, current loss 0.05326888766139746\n",
      "epoch 99, batch 10, current loss 0.10975430151447654\n",
      "epoch 99, batch 20, current loss 0.06684490977786481\n",
      "epoch 99, batch 30, current loss 0.12428741846233607\n",
      "epoch 100, batch 10, current loss 0.0940785196609795\n",
      "epoch 100, batch 20, current loss 0.05547282842453569\n",
      "epoch 100, batch 30, current loss 0.09772201860323548\n",
      "epoch 100 train accuracy: \n",
      "total_num:471, test accuracy:0.9936305732484076, positive_acc:0.9974025974025974, negative_acc:0.9767441860465116\n",
      "[[  84.    2.]\n",
      " [   1.  384.]]\n",
      "[72, 193]\n",
      "[163]\n",
      "-------------------\n",
      "epoch 100 test accuracy: \n",
      "total_num:96, test accuracy:0.9375, positive_acc:0.9615384615384616, negative_acc:0.8333333333333334\n",
      "[[ 15.   3.]\n",
      " [  3.  75.]]\n",
      "[0, 9, 88]\n",
      "[32, 38, 57]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "\n",
    "num_epochs = 100\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([3.5,1.0]).to(device))\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "print('choose SGD as optimizer')\n",
    "#optimizer = optim.Adam(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "#print('choose Adam as optimizer')\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    scheduler.step()\n",
    "    \n",
    "    Mouse_dataset = Mouse_sub_volumes(train_data, transform=transforms.Compose([Flip()]))\n",
    "    dataloader = DataLoader(Mouse_dataset, batch_size=12, shuffle=True, num_workers=4, drop_last = True)\n",
    "    train(net, device, dataloader, optimizer, criterion, epoch)\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print('epoch {} train accuracy: '.format(epoch+1))\n",
    "        train_Mouse_dataset = Mouse_sub_volumes(train_data)\n",
    "        train_dataloader = DataLoader(train_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "        train_dic = test(net, device, train_dataloader)\n",
    "        get_confusion_matrix(train_dic)\n",
    "        \n",
    "        print(\"-------------------\")\n",
    "        print('epoch {} test accuracy: '.format(epoch+1))\n",
    "        test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "        test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "        test_dic = test(net, device, test_dataloader)\n",
    "        get_confusion_matrix(test_dic)\n",
    "        \n",
    "        torch.save(net.state_dict(), './model/mut_clas_2020_02_05_e{}_global.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_probability(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            outputs = F.softmax(outputs)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy(), outputs.cpu().numpy()[0,0], outputs.cpu().numpy()[0,1]))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), './model/mut_clas_2019_01_15.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./model/mut_clas_2019_01_29_e260_global3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('train accuracy: ')\n",
    "# Mouse_dataset = Mouse_sub_volumes(all_train_data,train_idx)\n",
    "# train_dataloader = DataLoader(Mouse_dataset, batch_size=128,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "# test(net, device, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy: ')\n",
    "Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dic = test_with_probability(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_table = np.zeros([2,2])\n",
    "mut_to_nor = []\n",
    "nor_to_mul = []\n",
    "\n",
    "for i in range(len(test_dic)):\n",
    "    if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "        cross_table[0,0] += 1\n",
    "    elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "        cross_table[0,1] += 1\n",
    "        mut_to_nor.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "        cross_table[1,0] += 1\n",
    "        nor_to_mul.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "        cross_table[1,1] += 1\n",
    "print(cross_table)\n",
    "print(mut_to_nor)\n",
    "print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mut_to_nor:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/mul_img{}_cam.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nor_to_mul:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/nor_img{}_cam.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    if test_data[i][1] == 0:\n",
    "        img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "        img_save_data_path = './img/mul_img{}.nii'.format(i)\n",
    "        nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make input tensor require gradient\n",
    "    X.requires_grad_()\n",
    "    ##############################################################################\n",
    "    # Perform a forward and backward pass through the model to compute the gradient \n",
    "    # of the correct class score with respect to each input image. You first want \n",
    "    # to compute the loss over the correct scores (we'll combine losses across a batch\n",
    "    # by summing), and then compute the gradients with a backward pass.\n",
    "    ##############################################################################\n",
    "    scores = model(X)\n",
    "    \n",
    "    # Get the correct class computed scores.\n",
    "    scores = scores.gather(1, y.view(-1, 1)).squeeze()  \n",
    "    \n",
    "    # Backward pass, need to supply initial gradients of same tensor shape as scores.\n",
    "    scores.backward(torch.tensor(10.0).cuda(device))\n",
    "    \n",
    "    # Get gradient for image.\n",
    "    saliency = X.grad.data\n",
    "    \n",
    "    # Convert from 3d to 1d.\n",
    "    saliency = saliency.abs()\n",
    "    saliency = saliency.squeeze()\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    saliency = compute_saliency_maps(inputs, labels, net)\n",
    "    \n",
    "    max_value = torch.max(saliency)\n",
    "    saliency[saliency >= (max_value*0.2)] = 1\n",
    "    saliency[saliency < (max_value*0.2)] = 0\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.cpu().detach().numpy()+0.5),np.eye(4))\n",
    "    img_save_data_path = './saliency_map/img_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency.cpu().numpy()),np.eye(4))\n",
    "    saliency_save_data_path = './saliency_map/salency_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(saliency).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = torch.max(saliency)\n",
    "saliency[saliency >= (max_value*0.2)] = 1\n",
    "saliency[saliency < (max_value*0.2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.fc1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs= []\n",
    "# def hook(module, input, output):\n",
    "#     outputs.append(output)\n",
    "\n",
    "# net.conv8_bn.register_forward_hook(hook)\n",
    "# out = net(res)\n",
    "# out = net(res1)\n",
    "# print(outputs)\n",
    "\n",
    "\n",
    "# test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "# test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "# for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "#     inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "#     inputs = inputs.to(device)\n",
    "#     labels = labels.to(device)\n",
    "#     saliency = compute_saliency_maps(inputs, labels, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cpu()\n",
    "net.eval()\n",
    "\n",
    "fc_weight = net.fc1.weight.data\n",
    "\n",
    "res50_conv = nn.Sequential(*list(net.children())[:-3])\n",
    "for param in res50_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    saliency = compute_cam_maps(inputs, labels, net, fc_weight, res50_conv)\n",
    "    \n",
    "#     max_value = np.max(saliency)\n",
    "#     saliency[saliency >= (max_value*0.2)] = 1\n",
    "#     saliency[saliency < (max_value*0.2)] = 0\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.numpy()+0.5),np.eye(4))\n",
    "    img_save_data_path = './cam_map/img_label{}_{}.nii'.format(labels.numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency),np.eye(4))\n",
    "    saliency_save_data_path = './cam_map/salency_label{}_{}.nii'.format(labels.numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam represent class saliency map\n",
    "def compute_cam_maps(X, y, model, fc_weight, feature_extract): \n",
    "    model.eval()\n",
    "    \n",
    "    outputs = feature_extract(X).squeeze()\n",
    "    channels = outputs.shape[0]\n",
    "    saliency = outputs[0,...] * fc_weight[y, 0]\n",
    "    for i in range(1,channels):\n",
    "        saliency += outputs[i,...] * fc_weight[y, i]\n",
    "    saliency = zoom(saliency.numpy(), 8)\n",
    "    \n",
    "    saliency = saliency - np.min(saliency)\n",
    "    saliency = saliency / np.max(saliency)\n",
    "    \n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,96):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cpu()\n",
    "net.eval()\n",
    "\n",
    "fc_weight = net.fc1.weight.data\n",
    "\n",
    "res50_conv = nn.Sequential(*list(net.children())[:-2])\n",
    "for param in res50_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']\n",
    "    print(res50_conv(inputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
