{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "import nibabel as nib\n",
    "import glob\n",
    "from skimage import measure\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mutant_txt(path):\n",
    "    name_list = []\n",
    "    fo = open(path)\n",
    "    for line in fo:\n",
    "        striped_line = line.strip('\\n')\n",
    "        if striped_line != '':\n",
    "            name_list.append(striped_line)\n",
    "    return name_list\n",
    "\n",
    "def padded_minimum_size(label, min_size=(256,192,160)):\n",
    "    img_size = np.shape(label)\n",
    "    x_offset = max(0, round((min_size[0]-img_size[0])/2))\n",
    "    y_offset = max(0, round((min_size[1]-img_size[1])/2))\n",
    "    z_offset = max(0, round((min_size[2]-img_size[2])/2))\n",
    "        \n",
    "    padded_label=np.zeros((max(img_size[0],min_size[0]),\n",
    "                           max(img_size[1],min_size[1]),\n",
    "                           max(img_size[2],min_size[2])),np.uint8)\n",
    "    \n",
    "    padded_label[x_offset:x_offset+img_size[0], \n",
    "                 y_offset:y_offset+img_size[1], \n",
    "                 z_offset:z_offset+img_size[2]] = label\n",
    "    \n",
    "    return padded_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path1 = '/scratch/zq415/grammar_cor/isbi_2020/2seg-localization/data/all_data_bv_body_rotate'\n",
    "part_body_path2 = './part_body.txt'\n",
    "nii_save_path = './bv_body_nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = glob.glob(data_path1 + '/*.nii')\n",
    "part_body_names = read_mutant_txt(part_body_path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# body_size = []\n",
    "# img_size = []\n",
    "# count = 0\n",
    "# skip_num = 0\n",
    "\n",
    "# for each_file in files:\n",
    "#     base_name = os.path.basename(each_file)\n",
    "#     if base_name[:-4] in part_body_names:\n",
    "#         skip_num += 1\n",
    "#         continue\n",
    "# #     if base_name[:-4] != '20180307_En1_E14p5_M1_Em3abv_body_label':\n",
    "# #         continue\n",
    "# #     print(base_name[:-4])\n",
    "    \n",
    "#     label = nib.load(each_file)\n",
    "#     ori_label = np.uint8(label.get_data())\n",
    "#     label = np.uint8(ori_label > 0.5)\n",
    "    \n",
    "#     label_component = measure.label(label)\n",
    "#     max_component = 1\n",
    "#     component_num = np.unique(label_component)\n",
    "#     for current_component in range(2,len(component_num)+1):\n",
    "#         if np.sum(label_component == current_component) > np.sum(label_component == max_component):\n",
    "#             max_component = current_component\n",
    "    \n",
    "#     body_label = label_component == max_component\n",
    "    \n",
    "    \n",
    "#     body_slice = ndimage.find_objects(body_label)[0]\n",
    "#     body_size.append([body_slice[0].stop-body_slice[0].start,\n",
    "#                       body_slice[1].stop-body_slice[1].start,\n",
    "#                       body_slice[2].stop-body_slice[2].start])\n",
    "    \n",
    "#     img_size.append(body_label.shape)\n",
    "    \n",
    "#     body_centroid = np.round(ndimage.measurements.center_of_mass(body_label)).astype(int)\n",
    "    \n",
    "#     label_cut = ori_label[max(body_centroid[0]-128,0):min(body_centroid[0]+128,img_size[count][0]),\n",
    "#                           max(body_centroid[1]-96 ,0):min(body_centroid[1]+96 ,img_size[count][0]),\n",
    "#                           max(body_centroid[2]-80 ,0):min(body_centroid[2]+80 ,img_size[count][0])]\n",
    "#     if np.sum(label_cut) < 1000:\n",
    "#         print('something wrong')\n",
    "    \n",
    "    \n",
    "#     padded_label_cut = padded_minimum_size(label_cut)\n",
    "#     print(count, ': ', body_size[count], img_size[count], 'skip_num: ', skip_num)\n",
    "#     count += 1\n",
    "#     print(label_cut.shape, padded_label_cut.shape)\n",
    "    \n",
    "#     label_save_path = os.path.join(nii_save_path, base_name)\n",
    "    \n",
    "#     padded_label_cut_nib = nib.Nifti1Image(padded_label_cut, np.eye(4))\n",
    "#     nib.save(padded_label_cut_nib, label_save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####for checking body size\n",
    "bvbody_pickle_path = './data/All_raw_bv_body_data.pickle'\n",
    "bv_size = []\n",
    "img_size = []\n",
    "count = 0\n",
    "\n",
    "with open(bvbody_pickle_path, \"rb\") as input_file:\n",
    "    All_raw_bv_body_data = pickle.load(input_file)\n",
    "\n",
    "unalign_bv = {}\n",
    "\n",
    "for key in All_raw_bv_body_data:\n",
    "    bv_label = np.uint8(All_raw_bv_body_data[key] > 1.5)\n",
    "    img_size.append(bv_label.shape)\n",
    "#     bv_slice = ndimage.find_objects(bv_label)[0]\n",
    "#     bv_size.append([bv_slice[0].stop-bv_slice[0].start,\n",
    "#                     bv_slice[1].stop-bv_slice[1].start,\n",
    "#                     bv_slice[2].stop-bv_slice[2].start])\n",
    "    bv_centroid = np.round(ndimage.measurements.center_of_mass(bv_label)).astype(int)\n",
    "    label_cut = bv_label[max(bv_centroid[0]-64,0):min(bv_centroid[0]+64 ,img_size[count][0]),\n",
    "                          max(bv_centroid[1]-64 ,0):min(bv_centroid[1]+64 ,img_size[count][0]),\n",
    "                          max(bv_centroid[2]-64 ,0):min(bv_centroid[2]+64 ,img_size[count][0])]\n",
    "    \n",
    "    padded_label_cut = padded_minimum_size(label_cut, min_size=(128,128,128))\n",
    "    padded_label_cut = padded_label_cut[::2,::2,::2]\n",
    "    print(count, ': ', padded_label_cut.shape)\n",
    "    count += 1\n",
    "    \n",
    "    unalign_bv[key] = padded_label_cut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bv_save_path = './data/All_unalign_bv_data_64_64_64_down.pickle'\n",
    "save_file = open(bv_save_path, 'wb')\n",
    "pickle.dump(unalign_bv,save_file)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####for checking body size\n",
    "img_size = []\n",
    "unalign_body = {}\n",
    "count = 0 \n",
    "\n",
    "for key in All_raw_bv_body_data:\n",
    "    body_label = np.uint8(All_raw_bv_body_data[key] > 0.5)\n",
    "    img_size.append(body_label.shape)\n",
    "\n",
    "#     bv_slice = ndimage.find_objects(bv_label)[0]\n",
    "#     bv_size.append([bv_slice[0].stop-bv_slice[0].start,\n",
    "#                     bv_slice[1].stop-bv_slice[1].start,\n",
    "#                     bv_slice[2].stop-bv_slice[2].start])\n",
    "    body_centroid = np.round(ndimage.measurements.center_of_mass(body_label)).astype(int)\n",
    "    label_cut = body_label[max(body_centroid[0]-128,0):min(body_centroid[0]+128 ,img_size[count][0]),\n",
    "                          max(body_centroid[1]-128 ,0):min(body_centroid[1]+128 ,img_size[count][0]),\n",
    "                          max(body_centroid[2]-128 ,0):min(body_centroid[2]+128 ,img_size[count][0])]\n",
    "    \n",
    "    padded_label_cut = padded_minimum_size(label_cut, min_size=(256,256,256))\n",
    "    padded_label_cut = padded_label_cut[::2,::2,::2]\n",
    "    print(count, ': ', padded_label_cut.shape)\n",
    "    count += 1\n",
    "    \n",
    "    unalign_body[key] = padded_label_cut\n",
    "\n",
    "    \n",
    "body_save_path = './data/All_unalign_body_data_128_128_128_down.pickle'\n",
    "save_file = open(body_save_path, 'wb')\n",
    "pickle.dump(unalign_body,save_file)\n",
    "save_file.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####for checking body size\n",
    "img_size = []\n",
    "unalign_bv_body = {}\n",
    "count = 0 \n",
    "\n",
    "for key in All_raw_bv_body_data:\n",
    "    bv_body_label = All_raw_bv_body_data[key]\n",
    "    body_label = np.uint8(bv_body_label > 0.5)\n",
    "    img_size.append(body_label.shape)\n",
    "\n",
    "#     bv_slice = ndimage.find_objects(bv_label)[0]\n",
    "#     bv_size.append([bv_slice[0].stop-bv_slice[0].start,\n",
    "#                     bv_slice[1].stop-bv_slice[1].start,\n",
    "#                     bv_slice[2].stop-bv_slice[2].start])\n",
    "    body_centroid = np.round(ndimage.measurements.center_of_mass(body_label)).astype(int)\n",
    "    label_cut = bv_body_label[max(body_centroid[0]-128,0):min(body_centroid[0]+128 ,img_size[count][0]),\n",
    "                          max(body_centroid[1]-128 ,0):min(body_centroid[1]+128 ,img_size[count][0]),\n",
    "                          max(body_centroid[2]-128 ,0):min(body_centroid[2]+128 ,img_size[count][0])]\n",
    "    \n",
    "    padded_label_cut = padded_minimum_size(label_cut, min_size=(256,256,256))\n",
    "    padded_label_cut = padded_label_cut[::2,::2,::2]\n",
    "    print(count, ': ', padded_label_cut.shape)\n",
    "    count += 1\n",
    "    \n",
    "    unalign_bv_body[key] = padded_label_cut\n",
    "\n",
    "    \n",
    "bv_body_save_path = './data/All_unalign_bv_body_data_128_128_128_down.pickle'\n",
    "save_file = open(bv_body_save_path, 'wb')\n",
    "pickle.dump(unalign_bv_body,save_file)\n",
    "save_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(unalign_bv_body[key][:,:,50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "all_data={}\n",
    "miss_img1=0\n",
    "miss_img2=0\n",
    "miss_img3=0\n",
    "miss_name=[]\n",
    "bv_ratio = []\n",
    "size_min = 1000\n",
    "size_max = 0\n",
    "\n",
    "for folder1 in folder_list1:\n",
    "    data_path2=os.path.join(data_path1,folder1)\n",
    "    folder_list2=os.listdir(data_path2)\n",
    "    folder_list2=[x for x in folder_list2 if not x.startswith('.')]\n",
    "    for folder2 in folder_list2:\n",
    "        data_path3=os.path.join(data_path2,folder2)\n",
    "        folder_list3=os.listdir(data_path3)\n",
    "        folder_list3=[x for x in folder_list3 if (not x.endswith('labels.nii') and not x.startswith('.')\n",
    "                                                 and not x.endswith('filtered.nii'))]\n",
    "        for folder3 in folder_list3:\n",
    "            data_path4=os.path.join(data_path3,folder3)\n",
    "            #filtered_path=data_path4[:-4] + '.nii'#'_filtered.nii'\n",
    "            label_path = os.path.join(data_path4[:-4] + '_BV_labels.nii')\n",
    "            \n",
    "            img = nib.load(data_path4)\n",
    "            img = np.float32(img.get_data())\n",
    "\n",
    "#             filtered_img = nib.load(filtered_path)\n",
    "#             filtered_img = np.float32(filtered_img.get_data())\n",
    "            label = nib.load(label_path)\n",
    "            label = np.uint8(label.get_data())\n",
    "#             if np.shape(img) != np.shape(label) or np.shape(img) != np.shape(filtered_img):\n",
    "#                 miss_img1+=1\n",
    "#                 miss_name.append(data_path4)\n",
    "#                 continue\n",
    "#             if np.shape(img)[0] < 80 or np.shape(img)[1] < 80 or np.shape(img)[2] < 80:\n",
    "#                 miss_img2+=1\n",
    "#                 miss_name.append(data_path4)\n",
    "#                 continue\n",
    "#             if np.sum(label) <6000:\n",
    "#                 miss_img3+=1\n",
    "#                 miss_name.append(data_path4)\n",
    "#                 continue\n",
    "\n",
    "            all_data[count]=(data_path4,label_path)\n",
    "            count+=1\n",
    "            print(count,'  ',np.shape(img),'  ',np.shape(label),'  ',miss_img1, '  ',\n",
    "                  miss_img2,'  ', miss_img3,'  ', data_path4)\n",
    "            #bv_ratio.append(np.sum(label)/(np.prod(np.shape(img))+0.00001))\n",
    "            #print('bv ratio: {}'.format(bv_ratio[count-1]))\n",
    "#             if min(np.shape(img)) < size_min:\n",
    "#                 size_min = min(np.shape(img))\n",
    "#             if max(np.shape(img)) > size_max:\n",
    "#                 size_max = max(np.shape(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'All_2test_data_path.pickle'\n",
    "save_file = open(os.path.join(os.getcwd(),'data',save_name),'wb')\n",
    "pickle.dump(all_data,save_file)\n",
    "save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('min_size: {}, max_size: {}'.format(size_min, size_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(os.getcwd(),'data',save_name)\n",
    "with open(file_path,'rb') as f:\n",
    "    data_dic = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_bv_ratio = 0\n",
    "for i in range(len(bv_ratio)):\n",
    "    avg_bv_ratio += bv_ratio[i]\n",
    "avg_bv_ratio /= len(bv_ratio)\n",
    "print(avg_bv_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
