{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/share/apps/python3/3.6.3/intel/lib/python3.6/site-packages/h5py-2.7.1-py3.6-linux-x86_64.egg/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "from torchcontrib.optim import SWA\n",
    "\n",
    "from mutant_cla_network import *\n",
    "from utility_func import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_names = read_mutant_txt('mutant_imgs.txt')\n",
    "data_base_path = '/scratch/zq415/grammar_cor/mutant_detect/mutant_cla/data'\n",
    "data_nii_path = '/scratch/zq415/grammar_cor/mutant_detect/mutant_cla/bv_body_nii'\n",
    "save_name = 'All_data_256_196_160_down.pickle'\n",
    "# 'All_data_256_196_160.pickle'\n",
    "# save_name = 'All_bv_data_64_64_40_down.pickle'\n",
    "# save_name = 'All_body_data_128_98_80_down.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(os.path.join(data_base_path,save_name)):\n",
    "    with open(os.path.join(data_base_path, save_name), \"rb\") as input_file:\n",
    "        all_train_data = pickle.load(input_file)\n",
    "else:\n",
    "    files = glob.glob(data_nii_path + '/*.nii')\n",
    "    all_train_data = {}\n",
    "    for i in tqdm(range(len(files))):\n",
    "        base_name = os.path.basename(files[i])[:-17]\n",
    "        label = nib.load(files[i])\n",
    "        ori_label = np.uint8(label.get_data()[::2,::2,::2])\n",
    "        print(ori_label.shape)\n",
    "        all_train_data[base_name] = ori_label\n",
    "    if not os.path.exists(os.path.join(data_base_path,save_name)):\n",
    "        save_file = open(os.path.join(data_base_path, save_name),'wb')\n",
    "        pickle.dump(all_train_data,save_file)\n",
    "        save_file.close() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 ['20170207_En1_E13_E12a_Mut', '20170207_En1_E13_E12b_Mut', '20170207_En1_E13_E12c_Mut', '20170207_En1_E13_E12d_Mut', '20170727_En1_E13_E1a_Mut', '20170727_En1_E13_E1b_Mut', '20161222_En1_E13_E1a_Mut', '20161222_En1_E13_E1b_Mut', '20161222_En1_E13_E1c_Mut', '20180202_En1_E14_E4a_mut', '20180202_En1_E14_E4b_Mut', '20171211_En1_E10_E4b', '20170705_En1_E12_E1a_filt', '20171004_En1_E13_E5b_Mut', '20171009_En1_E12_E11a', '20161219_En1_E10_E5Ma', '20161223_En1_E14_E1a_Mut']\n"
     ]
    }
   ],
   "source": [
    "mutant_group = [(9,10), (12,13,14), (16,17,18,19), (36,37), (38,39), (42,43), (44,45,46,47), (48,49,50,51), (52,53), (54,55),\n",
    "(56,57,58), (59,60,61), (63,64), (66,67,68), (69,70,71), (73,74), (75,76), (77,78,79), (80,81,82,83,84,85,86,87),\n",
    "(89,90), (91,92), (93,94), (95,96,97), (98,99), (100,101,102)]\n",
    "group_list = []\n",
    "for one_group in mutant_group:\n",
    "    for ii in range(len(one_group)):\n",
    "        group_list.append(one_group[ii])\n",
    "single_mutant = [i for i in range(len(mutant_names)) if i not in group_list]\n",
    "\n",
    "test_mut_names = []\n",
    "for i in range(2,len(mutant_group),6):\n",
    "    for ii in range(len(mutant_group[i])):\n",
    "        test_mut_names.append(mutant_names[mutant_group[i][ii]])\n",
    "\n",
    "for i in range(2,len(single_mutant),6):\n",
    "    test_mut_names.append(mutant_names[single_mutant[i]])\n",
    "\n",
    "print(len(test_mut_names),test_mut_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #####for bv or body\n",
    "# train_data = []\n",
    "# test_data = []\n",
    "# seed_num = 0\n",
    "# for name in all_train_data:\n",
    "#     if name in mutant_names:\n",
    "#         if name in test_mut_names:\n",
    "#             test_data.append((all_train_data[name]-0.5, 0))\n",
    "#             print('mutant: ',name)\n",
    "#         else:\n",
    "#             train_data.append((all_train_data[name]-0.5,0))\n",
    "#     else:\n",
    "#         random.seed(seed_num*8)\n",
    "# #         random.seed(seed_num*9)\n",
    "#         seed_num += 1\n",
    "#         if random.uniform(0,1) < 0.16:\n",
    "#             test_data.append((all_train_data[name]-0.5,1))\n",
    "#             print('normal: ',name)\n",
    "#         else:\n",
    "#             train_data.append((all_train_data[name]-0.5,1))\n",
    "\n",
    "# print(len(test_data))\n",
    "# print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "102 440\n"
     ]
    }
   ],
   "source": [
    "mutant_num = 0\n",
    "normal_num = 0\n",
    "\n",
    "for name in all_train_data:\n",
    "    if name in mutant_names:\n",
    "        mutant_num += 1\n",
    "    else:\n",
    "        normal_num += 1\n",
    "        \n",
    "print(mutant_num, normal_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal:  20180228_En1_E13p5_Ext_E1a\n",
      "normal:  20180302_En1_E14.5_Ext_E11a_reg\n",
      "normal:  20171212_En1_E11_E8a\n",
      "normal:  20180202_En1_E14_E12a\n",
      "normal:  20171003_En1_E13_E8a_reg\n",
      "normal:  20170129_En1_E11_E2a_reg\n",
      "normal:  20170206_En1_E12_E3a\n",
      "normal:  20170320_En1_E11_E6a\n",
      "normal:  20180205_En1_E11_E1c_reg\n",
      "mutant:  20180202_En1_E14_E4a_mut\n",
      "normal:  20180302_En1_E14.5_Ext_E8a_reg\n",
      "normal:  20180904_En1_E11p5_4a_007\n",
      "mutant:  20170727_En1_E13_E1a_Mut\n",
      "normal:  20170313_EN1_E10_E3b_reg_filt\n",
      "normal:  20161207_En1_E14_E4a\n",
      "normal:  20170619_En1_E12_E2a\n",
      "normal:  20180202_En1_E14_E1a\n",
      "normal:  20180226_En1_E11p5_Em2a\n",
      "normal:  20161116_En1_E12_E6a_reg\n",
      "normal:  20161222_En1_E13_E2a\n",
      "normal:  20171002_En1_E11_E1a\n",
      "normal:  20170315_En1_E12_E2b\n",
      "mutant:  20161222_En1_E13_E1c_Mut\n",
      "normal:  20170331_En1_E14p_E2a\n",
      "normal:  20170705_En1_E12_E5a_filt\n",
      "normal:  20161116_En1_E12_E2a_reg\n",
      "normal:  20170619_En1_E12_Ex_E12a_reg\n",
      "normal:  20180226_En1_E11p5_Em1a\n",
      "mutant:  20170207_En1_E13_E12a_Mut\n",
      "normal:  20170314_En1_E11_E4b\n",
      "mutant:  20161222_En1_E13_E1b_Mut\n",
      "normal:  20180202_En1_E14_E7a_reg\n",
      "normal:  20170301_En1_E12_E1b_filt\n",
      "normal:  20180302_En1_E14.5_Ext_E1a\n",
      "normal:  20180228_En1_E13p5_Ext_E4a_reg\n",
      "normal:  20170330_En1_E13_E2a\n",
      "normal:  20171009_En1_E12_E3a\n",
      "normal:  20180207_En1_E13_E1b\n",
      "normal:  20180228_En1_E13p5_Ext_E7a_reg\n",
      "normal:  20180302_En1_E14.5_Em2a\n",
      "mutant:  20171004_En1_E13_E5b_Mut\n",
      "normal:  20170706_En1_E13_E7a_reg\n",
      "normal:  20170316_En1_E13_E3a\n",
      "normal:  20180905_EN1_E14p5_Ext_E5a_027\n",
      "normal:  20170314_En1_E11_E2b\n",
      "normal:  20171003_En1_E13_E3a_reg\n",
      "normal:  20180307_En1_E14p5_M1_Em1a\n",
      "normal:  20180201_En1_M2_E13_E5a\n",
      "mutant:  20170207_En1_E13_E12c_Mut\n",
      "normal:  20180905_EN1_E14p5_E3a_020\n",
      "normal:  20170129_En1_E11_E3a_reg\n",
      "normal:  20171002_En1_E11_E4a\n",
      "normal:  20161115_En1_E11_E1a_reg\n",
      "normal:  20171003_En1_E13_E5c_reg\n",
      "normal:  20170718_En1_E12_E4a_reg\n",
      "normal:  20180228_En1_E13p5_Ext_E7a\n",
      "normal:  20180228_En1_E13p5_Ext_E11a_reg\n",
      "normal:  20170626_En1_E13p5_E5a\n",
      "mutant:  20161222_En1_E13_E1a_Mut\n",
      "mutant:  20161219_En1_E10_E5Ma\n",
      "normal:  20180130_En1_E11p5_E1a_reg\n",
      "mutant:  20170207_En1_E13_E12b_Mut\n",
      "normal:  20170206_En1_E12_E4a\n",
      "normal:  20171003_En1_E13_E10a_reg\n",
      "normal:  20170718_En1_E12_E3a_reg\n",
      "normal:  20180307_En1_E14p5_M1_Ext_Em16a\n",
      "normal:  20180205_En1_E11_E1c\n",
      "normal:  20170327_En1_E10_E4a\n",
      "mutant:  20180202_En1_E14_E4b_Mut\n",
      "normal:  20180228_En1_E13p5_Ext_E3a\n",
      "normal:  20170301_En1_E12_E3a_filt\n",
      "normal:  20171002_En1_E11_E3a\n",
      "normal:  20180228_En1_E13p5_E5a_reg\n",
      "normal:  20180130_En1_E12p5_E2b_reg\n",
      "normal:  20180306_En1_E13p5_M1_Em3a\n",
      "mutant:  20161223_En1_E14_E1a_Mut\n",
      "normal:  20161128_En1_E14_E1R-filt\n",
      "normal:  20170706_En1_E13_E8a_reg\n",
      "mutant:  20171211_En1_E10_E4b\n",
      "mutant:  20170207_En1_E13_E12d_Mut\n",
      "normal:  20180905_EN1_E14p5_Ext_E1a_023\n",
      "normal:  20180226_En1_E10p5_Em2a\n",
      "normal:  20161128_En1_E14_E2b-filt\n",
      "normal:  20161121_En1_E3a_reg-filt\n",
      "mutant:  20170705_En1_E12_E1a_filt\n",
      "normal:  20180201_En1_M2_E13_E3b\n",
      "normal:  20180202_En1_E14_E8a\n",
      "mutant:  20170727_En1_E13_E1b_Mut\n",
      "normal:  20180205_En1_E11_E1b\n",
      "normal:  20180905_EN1_E14p5_Ext_E6a_028\n",
      "normal:  20161223_En1_E14_Ext_E1a\n",
      "normal:  20170706_En1_E13_E3a_reg\n",
      "mutant:  20171009_En1_E12_E11a\n",
      "93\n",
      "449\n"
     ]
    }
   ],
   "source": [
    "#####for bv and body\n",
    "train_data = []\n",
    "test_data = []\n",
    "seed_num = 0\n",
    "\n",
    "for name in all_train_data:\n",
    "    if name in mutant_names:\n",
    "        if name in test_mut_names:\n",
    "            test_data.append((all_train_data[name]-1.0, 0))\n",
    "            print('mutant: ',name)\n",
    "        else:\n",
    "            train_data.append((all_train_data[name]-1.0,0))\n",
    "    else:\n",
    "        random.seed(seed_num*8)\n",
    "#         random.seed(seed_num*9)\n",
    "        seed_num += 1\n",
    "        if random.uniform(0,1) < 0.16:\n",
    "            test_data.append((all_train_data[name]-1.0,1))\n",
    "            print('normal: ',name)\n",
    "        else:\n",
    "            train_data.append((all_train_data[name]-1.0,1))\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n",
      "There are 355214 parameters in the model\n",
      "choose SGD as optimizer\n",
      "epoch 1, batch 10, current loss 0.703300940990448\n",
      "epoch 1, batch 20, current loss 0.6585101664066315\n",
      "epoch 1, batch 30, current loss 0.6865073204040527\n",
      "epoch 1, batch 40, current loss 0.7826775312423706\n",
      "epoch 1, batch 50, current loss 0.719043105840683\n",
      "epoch 2, batch 10, current loss 0.7033322274684906\n",
      "epoch 2, batch 20, current loss 0.6509332716464996\n",
      "epoch 2, batch 30, current loss 0.649322235584259\n",
      "epoch 2, batch 40, current loss 0.7562605082988739\n",
      "epoch 2, batch 50, current loss 0.6646083712577819\n",
      "epoch 3, batch 10, current loss 0.6654145181179046\n",
      "epoch 3, batch 20, current loss 0.6608971148729325\n",
      "epoch 3, batch 30, current loss 0.6801113188266754\n",
      "epoch 3, batch 40, current loss 0.68841752409935\n",
      "epoch 3, batch 50, current loss 0.6764464497566223\n",
      "epoch 4, batch 10, current loss 0.6558421969413757\n",
      "epoch 4, batch 20, current loss 0.6336130678653717\n",
      "epoch 4, batch 30, current loss 0.6792974591255188\n",
      "epoch 4, batch 40, current loss 0.7191226691007614\n",
      "epoch 4, batch 50, current loss 0.6674332231283188\n",
      "epoch 5, batch 10, current loss 0.6052678555250168\n",
      "epoch 5, batch 20, current loss 0.654682508111\n",
      "epoch 5, batch 30, current loss 0.7359089314937591\n",
      "epoch 5, batch 40, current loss 0.6812297642230988\n",
      "epoch 5, batch 50, current loss 0.6819976419210434\n",
      "epoch 6, batch 10, current loss 0.6913365662097931\n",
      "epoch 6, batch 20, current loss 0.6433164298534393\n",
      "epoch 6, batch 30, current loss 0.6018303573131562\n",
      "epoch 6, batch 40, current loss 0.6476084649562835\n",
      "epoch 6, batch 50, current loss 0.6565970599651336\n",
      "epoch 7, batch 10, current loss 0.5829973936080932\n",
      "epoch 7, batch 20, current loss 0.733976149559021\n",
      "epoch 7, batch 30, current loss 0.6441820621490478\n",
      "epoch 7, batch 40, current loss 0.5889114677906037\n",
      "epoch 7, batch 50, current loss 0.6734253764152527\n",
      "epoch 8, batch 10, current loss 0.646973779797554\n",
      "epoch 8, batch 20, current loss 0.6052692383527756\n",
      "epoch 8, batch 30, current loss 0.6285323709249496\n",
      "epoch 8, batch 40, current loss 0.6126207679510116\n",
      "epoch 8, batch 50, current loss 0.6175768494606018\n",
      "epoch 9, batch 10, current loss 0.5599540174007416\n",
      "epoch 9, batch 20, current loss 0.6881427228450775\n",
      "epoch 9, batch 30, current loss 0.6680835247039795\n",
      "epoch 9, batch 40, current loss 0.6522747844457626\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-5fd7f78e8912>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mMouse_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMouse_sub_volumes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#transform=transforms.Compose([Flip()])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMouse_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop_last\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch {} train accuracy: '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/scratch/zq415/grammar_cor/mutant_detect/mutant_cla/utility_func.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, device, train_loader, optimizer, criterion, epoch)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m         \u001b[0;31m# print statistics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m         \u001b[0mi_batch\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi_batch\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# net = VGG_net()\n",
    "# #net.apply(weight_init)\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "#     net = nn.DataParallel(net)\n",
    "# net.to(device)\n",
    "# print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "\n",
    "# num_epochs = 120\n",
    "# criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([3.5,1.0]).to(device))\n",
    "\n",
    "# # optimizer_base = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "# # optimizer = SWA(optimizer_base, swa_start=60, swa_freq=5)\n",
    "\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "# print('choose SGD as optimizer')\n",
    "# #optimizer = optim.Adam(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "# #print('choose Adam as optimizer')\n",
    "\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=70, gamma=0.5)\n",
    "\n",
    "# for epoch in range(num_epochs):\n",
    "#     scheduler.step()\n",
    "    \n",
    "#     Mouse_dataset = Mouse_sub_volumes(train_data)#transform=transforms.Compose([Flip()])\n",
    "#     dataloader = DataLoader(Mouse_dataset, batch_size=8, shuffle=True, num_workers=4, drop_last = True)\n",
    "#     train(net, device, dataloader, optimizer, criterion, epoch)\n",
    "#     if (epoch + 1) % 10 == 0:\n",
    "#         print('epoch {} train accuracy: '.format(epoch+1))\n",
    "#         train_Mouse_dataset = Mouse_sub_volumes(train_data)\n",
    "#         train_dataloader = DataLoader(train_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "#         train_dic = test(net, device, train_dataloader)\n",
    "#         get_confusion_matrix(train_dic)\n",
    "        \n",
    "#         print(\"-------------------\")\n",
    "#         print('epoch {} test accuracy: '.format(epoch+1))\n",
    "#         test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "#         test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "#         test_dic = test(net, device, test_dataloader)\n",
    "#         get_confusion_matrix(test_dic)\n",
    "        \n",
    "#         torch.save(net.state_dict(), './model/mut_clas_2020_04_01_e{}_body.pth'.format(epoch+1))\n",
    "        \n",
    "# train_test_data = [train_data, test_data]\n",
    "# save_file = open('./model/mut_clas_2020_04_01_e{}_body_data.pickle'.format(epoch+1),'wb')\n",
    "# pickle.dump(train_test_data, save_file)\n",
    "# save_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_probability(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            outputs = F.softmax(outputs)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy(), outputs.cpu().numpy()[0,0], outputs.cpu().numpy()[0,1]))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load a trained model and test to get the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./model/mut_clas_2020_03_11_e100_bv_body.pth'))\n",
    "\n",
    "with open('./model/mut_clas_2020_03_11_e100_bv_body_data.pickle', 'rb') as input_file:\n",
    "    train_data, test_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('train accuracy: ')\n",
    "Mouse_dataset = Mouse_sub_volumes(train_data)\n",
    "train_dataloader = DataLoader(Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "train_dic = test_with_probability(net, device, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy: ')\n",
    "Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "test_dic = test_with_probability(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_table = np.zeros([2,2])\n",
    "mut_to_nor = []\n",
    "nor_to_mul = []\n",
    "for i in range(len(test_dic)):\n",
    "    if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "        cross_table[0,0] += 1\n",
    "    elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "        cross_table[0,1] += 1\n",
    "        mut_to_nor.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "        cross_table[1,0] += 1\n",
    "        nor_to_mul.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "        cross_table[1,1] += 1\n",
    "print(cross_table)\n",
    "print(mut_to_nor)\n",
    "print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the saliency map using gradeint backpropogation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make input tensor require gradient\n",
    "    X.requires_grad_()\n",
    "    ##############################################################################\n",
    "    # Perform a forward and backward pass through the model to compute the gradient \n",
    "    # of the correct class score with respect to each input image. You first want \n",
    "    # to compute the loss over the correct scores (we'll combine losses across a batch\n",
    "    # by summing), and then compute the gradients with a backward pass.\n",
    "    ##############################################################################\n",
    "    scores = model(X)\n",
    "    \n",
    "    # Get the correct class computed scores.\n",
    "    scores = scores.gather(1, y.view(-1, 1)).squeeze()  \n",
    "    \n",
    "    # Backward pass, need to supply initial gradients of same tensor shape as scores.\n",
    "    scores.backward(torch.tensor(10.0).cuda(device))\n",
    "    \n",
    "    # Get gradient for image.\n",
    "    saliency = X.grad.data\n",
    "    \n",
    "    # Convert from 3d to 1d.\n",
    "    saliency = saliency.abs()\n",
    "    saliency = saliency.squeeze()\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    saliency = compute_saliency_maps(inputs, labels, net)\n",
    "    \n",
    "    max_value = torch.max(saliency)\n",
    "    print(torch.max(saliency), torch.min(saliency))\n",
    "    saliency[saliency >= (max_value*0.2)] = 100\n",
    "    saliency[saliency < (max_value*0.2)] = 0\n",
    "    saliency *= 0.01\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.cpu().detach().numpy()+1.0),np.eye(4))\n",
    "    img_save_data_path = './saliency_map/img_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    print(i_batch, ' saliency num: ', np.sum(saliency.cpu().numpy()))\n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency.cpu().numpy()),np.eye(4))\n",
    "    saliency_save_data_path = './saliency_map/salency_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "    \n",
    "# 5,6,8,9,10,11,12,33,27"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
