{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def read_mutant_txt(path):\n",
    "    name_list = []\n",
    "    fo = open(path)\n",
    "    for line in fo:\n",
    "        striped_line = line.strip('\\n')\n",
    "        if striped_line != '':\n",
    "            name_list.append(striped_line)\n",
    "    return name_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_names = read_mutant_txt('mutant_imgs.txt')\n",
    "data_base_path = '/scratch/zq415/grammar_cor/mutant_detect/data'\n",
    "data_folder_list = ['20180419_newdata_nii_with_filtered', 'new_data_20180522_nii', 'organized_data_nii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_name = 'All_data_112_64_64.pickle'\n",
    "with open(os.path.join(os.getcwd(),'data',save_name), \"rb\") as input_file:\n",
    "    all_train_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18 ['20170207_En1_E13_E3_Mut', '20170207_En1_E13_E3c_Mut', '20170207_En1_E13_E3d_Mut', '20161206_En1_E13_E3a', '20161206_En1_E13_E3b', '20161206_En1_E13_E3c', '20161206_En1_E13_E3d', '20180131_En1_E12_E5a_Mut', '20180131_En1_E12_E5b', '20180131_En1_E12_E5c_Mut', '20180202_En1_E14_E3a_Mut', '20180202_En1_E14_E3b_Mut', '20171211_En1_E10_E1a', '20170619_En1_E12_E3a', '20170706_En1_E13_E11a_Mut_reg', '20171009_En1_E12_E10a', '20171211_En1_E13_E5a_Mut_Ext', '20180201_En1_M2_E13_E4a']\n"
     ]
    }
   ],
   "source": [
    "mutant_group = [(9,10), (12,13,14), (16,17,18,19), (36,37), (38,39), (42,43), (44,45,46,47), (48,49,50,51), (52,53), (54,55),\n",
    "(56,57,58), (59,60,61), (63,64), (66,67,68), (69,70,71), (73,74), (75,76), (77,78,79), (80,81,82,83,84,85,86,87),\n",
    "(89,90), (91,92), (93,94), (95,96,97), (98,99), (100,101,102)]\n",
    "\n",
    "group_list = []\n",
    "for one_group in mutant_group:\n",
    "    for ii in range(len(one_group)):\n",
    "        group_list.append(one_group[ii])\n",
    "single_mutant = [i for i in range(len(mutant_names)) if i not in group_list]\n",
    "\n",
    "test_mut_names = []\n",
    "for i in range(1,len(mutant_group),6):\n",
    "    for ii in range(len(mutant_group[i])):\n",
    "        test_mut_names.append(mutant_names[mutant_group[i][ii]])\n",
    "\n",
    "for i in range(1,len(single_mutant),6):\n",
    "    test_mut_names.append(mutant_names[single_mutant[i]])\n",
    "    \n",
    "print(len(test_mut_names),test_mut_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(all_train_data)):\n",
    "#     if all_train_data[i][2] in mutant_names:\n",
    "#         img_nft = nib.Nifti1Image(all_train_data[i][3],np.eye(4))\n",
    "#         img_save_data_path = './img/{}.nii'.format(all_train_data[i][2])\n",
    "#         nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "96\n",
      "471\n"
     ]
    }
   ],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] in mutant_names:\n",
    "        if all_train_data[i][2] in test_mut_names:\n",
    "            test_data.append((all_train_data[i][3]-0.5, 0 ))\n",
    "        else:\n",
    "            train_data.append((all_train_data[i][3]-0.5,0))\n",
    "    else:\n",
    "        random.seed(i*8)\n",
    "        if random.uniform(0,1) < 0.16:\n",
    "            test_data.append((all_train_data[i][3]-0.5,1))\n",
    "        else:\n",
    "            train_data.append((all_train_data[i][3]-0.5,1))\n",
    "\n",
    "print(len(test_data))\n",
    "print(len(train_data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img_nft = nib.Nifti1Image(np.squeeze(all_train_data[193]),np.eye(4))\n",
    "#img_save_data_path = './img/mul_img.nii'\n",
    "#nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Mouse_sub_volumes(Dataset):\n",
    "    \"\"\"Mouse sub-volumes BV dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, all_data , transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            all_whole_volumes: Contain all the padded whole BV volumes as a dic\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.all_data = all_data\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self, num):\n",
    "        \n",
    "        current_img, label = self.all_data[num]\n",
    "        \n",
    "        img = np.float32(current_img[np.newaxis,...])\n",
    "        sample = {'image': img, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Flip the image for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,ori_probability=0.20):\n",
    "        self.ori_probability = ori_probability\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['image'], sample['label']\n",
    "            random_choise1=random.choice([1,2,3,4,5,6,7,8])\n",
    "            img[0,...] = {1: lambda x: x,\n",
    "                          2: lambda x: x[::-1,:,:],\n",
    "                          3: lambda x: x[:,::-1,:],\n",
    "                          4: lambda x: x[:,:,::-1],\n",
    "                          5: lambda x: x[::-1,::-1,:],\n",
    "                          6: lambda x: x[::-1,:,::-1],\n",
    "                          7: lambda x: x[:,::-1,::-1],\n",
    "                          8: lambda x: x[::-1,::-1,::-1]\n",
    "                          }[random_choise1](img[0,...])\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    def __init__(self,conv_drop_rate=0.15,linear_drop_rate=0.4):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=8, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv1_bn = nn.BatchNorm3d(8)\n",
    "        self.conv2 = nn.Conv3d(in_channels=8, out_channels=8, kernel_size=3,stride=1,padding=2, dilation=2)\n",
    "        self.conv2_bn = nn.BatchNorm3d(8)\n",
    "        self.pool1 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout1 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=8, out_channels=12, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv3_bn = nn.BatchNorm3d(12)\n",
    "        self.conv4 = nn.Conv3d(in_channels=12, out_channels=12, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv4_bn = nn.BatchNorm3d(12)\n",
    "        self.pool2 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout2 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv5 = nn.Conv3d(in_channels=12, out_channels=18, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv5_bn = nn.BatchNorm3d(18)\n",
    "        self.conv6 = nn.Conv3d(in_channels=18, out_channels=18, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv6_bn = nn.BatchNorm3d(18)\n",
    "        self.pool3 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout3 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv7 = nn.Conv3d(in_channels=18, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv7_bn = nn.BatchNorm3d(24)\n",
    "        self.conv8 = nn.Conv3d(in_channels=24, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv8_bn = nn.BatchNorm3d(24)\n",
    "        self.pool4 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout4 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.fc1 = nn.Linear(7*4*4*24, 128)\n",
    "        self.fc1_bn = nn.BatchNorm1d(128)\n",
    "        self.dropout5 = nn.Dropout(linear_drop_rate)\n",
    "        self.fc2 = nn.Linear(128, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1_bn(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(self.pool1(self.conv2_bn(F.relu(self.conv2(x)))))\n",
    "        \n",
    "        x = self.conv3_bn(F.relu(self.conv3(x)))\n",
    "        x = self.dropout2(self.pool2(self.conv4_bn(F.relu(self.conv4(x)))))\n",
    "        \n",
    "        x = self.conv5_bn(F.relu(self.conv5(x)))\n",
    "        x = self.dropout3(self.pool3(self.conv6_bn(F.relu(self.conv6(x)))))\n",
    "        \n",
    "        x = self.conv7_bn(F.relu(self.conv7(x)))\n",
    "        x = self.dropout4(self.pool4(self.conv8_bn(F.relu(self.conv8(x)))))\n",
    "        \n",
    "        x = x.view(-1, 7*4*4*24)\n",
    "        x = self.dropout5(self.fc1_bn(F.relu(self.fc1(x))))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        i_batch += 1\n",
    "        if i_batch % 10 == 0:\n",
    "            print(\"epoch {}, batch {}, current loss {}\".format(epoch+1,i_batch,running_loss/10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy()))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels\n",
    "\n",
    "def get_confusion_matrix(true_predicted_labels):\n",
    "    cross_table = np.zeros([2,2])\n",
    "    mut_to_nor = []\n",
    "    nor_to_mul = []\n",
    "    test_dic = true_predicted_labels\n",
    "    for i in range(len(test_dic)):\n",
    "        if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "            cross_table[0,0] += 1\n",
    "        elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "            cross_table[0,1] += 1\n",
    "            mut_to_nor.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "            cross_table[1,0] += 1\n",
    "            nor_to_mul.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "            cross_table[1,1] += 1\n",
    "    print(cross_table)\n",
    "    print(mut_to_nor)\n",
    "    print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n",
      "There are 395298 parameters in the model\n",
      "choose SGD as optimizer\n",
      "epoch 1, batch 10, current loss 0.780630749464035\n",
      "epoch 1, batch 20, current loss 0.6993573904037476\n",
      "epoch 1, batch 30, current loss 0.7187361419200897\n",
      "epoch 2, batch 10, current loss 0.8803674757480622\n",
      "epoch 2, batch 20, current loss 0.767909699678421\n",
      "epoch 2, batch 30, current loss 0.7378782570362091\n",
      "epoch 3, batch 10, current loss 0.7800279140472413\n",
      "epoch 3, batch 20, current loss 0.8735969960689545\n",
      "epoch 3, batch 30, current loss 0.7954321920871734\n",
      "epoch 4, batch 10, current loss 0.681000730395317\n",
      "epoch 4, batch 20, current loss 0.8097834885120392\n",
      "epoch 4, batch 30, current loss 0.7066658973693848\n",
      "epoch 5, batch 10, current loss 0.6601932972669602\n",
      "epoch 5, batch 20, current loss 0.7193651497364044\n",
      "epoch 5, batch 30, current loss 0.8450327605009079\n",
      "epoch 6, batch 10, current loss 0.6180893898010253\n",
      "epoch 6, batch 20, current loss 0.6529900521039963\n",
      "epoch 6, batch 30, current loss 0.8709400534629822\n",
      "epoch 7, batch 10, current loss 0.8530548751354218\n",
      "epoch 7, batch 20, current loss 0.7902727246284484\n",
      "epoch 7, batch 30, current loss 0.6424369633197784\n",
      "epoch 8, batch 10, current loss 0.8078270763158798\n",
      "epoch 8, batch 20, current loss 0.8634432882070542\n",
      "epoch 8, batch 30, current loss 0.7336705565452576\n",
      "epoch 9, batch 10, current loss 0.7402680039405822\n",
      "epoch 9, batch 20, current loss 0.8413356870412827\n",
      "epoch 9, batch 30, current loss 0.8842741310596466\n",
      "epoch 10, batch 10, current loss 0.8191315263509751\n",
      "epoch 10, batch 20, current loss 0.7010567754507064\n",
      "epoch 10, batch 30, current loss 0.8191858291625976\n",
      "epoch 11, batch 10, current loss 0.7043878048658371\n",
      "epoch 11, batch 20, current loss 0.7006902992725372\n",
      "epoch 11, batch 30, current loss 0.699004128575325\n",
      "epoch 12, batch 10, current loss 0.828421127796173\n",
      "epoch 12, batch 20, current loss 0.634417524933815\n",
      "epoch 12, batch 30, current loss 0.7497350305318833\n",
      "epoch 13, batch 10, current loss 0.7118618786334991\n",
      "epoch 13, batch 20, current loss 0.595560359954834\n",
      "epoch 13, batch 30, current loss 0.7775439828634262\n",
      "epoch 14, batch 10, current loss 0.6541759103536606\n",
      "epoch 14, batch 20, current loss 0.6628102272748947\n",
      "epoch 14, batch 30, current loss 0.7814155220985413\n",
      "epoch 15, batch 10, current loss 0.7602196574211121\n",
      "epoch 15, batch 20, current loss 0.6894196033477783\n",
      "epoch 15, batch 30, current loss 0.7344069540500641\n",
      "epoch 16, batch 10, current loss 0.7401461333036423\n",
      "epoch 16, batch 20, current loss 0.7936131298542023\n",
      "epoch 16, batch 30, current loss 0.6851756751537323\n",
      "epoch 17, batch 10, current loss 0.7086149007081985\n",
      "epoch 17, batch 20, current loss 0.7674027353525161\n",
      "epoch 17, batch 30, current loss 0.5859940618276596\n",
      "epoch 18, batch 10, current loss 0.7454331636428833\n",
      "epoch 18, batch 20, current loss 0.6488468408584595\n",
      "epoch 18, batch 30, current loss 0.685975655913353\n",
      "epoch 19, batch 10, current loss 0.6188302218914032\n",
      "epoch 19, batch 20, current loss 0.696657407283783\n",
      "epoch 19, batch 30, current loss 0.6582323521375656\n",
      "epoch 20, batch 10, current loss 0.7032924443483353\n",
      "epoch 20, batch 20, current loss 0.6700075805187226\n",
      "epoch 20, batch 30, current loss 0.7117140650749206\n",
      "epoch 21, batch 10, current loss 0.7250197887420654\n",
      "epoch 21, batch 20, current loss 0.6908576607704162\n",
      "epoch 21, batch 30, current loss 0.7553865224123001\n",
      "epoch 22, batch 10, current loss 0.7541233539581299\n",
      "epoch 22, batch 20, current loss 0.7218606829643249\n",
      "epoch 22, batch 30, current loss 0.728741917014122\n",
      "epoch 23, batch 10, current loss 0.6903376996517181\n",
      "epoch 23, batch 20, current loss 0.7235353589057922\n",
      "epoch 23, batch 30, current loss 0.6918236315250397\n",
      "epoch 24, batch 10, current loss 0.7296857476234436\n",
      "epoch 24, batch 20, current loss 0.6811264485120774\n",
      "epoch 24, batch 30, current loss 0.7283284306526184\n",
      "epoch 25, batch 10, current loss 0.690184873342514\n",
      "epoch 25, batch 20, current loss 0.7506382882595062\n",
      "epoch 25, batch 30, current loss 0.6826966792345047\n",
      "epoch 26, batch 10, current loss 0.8115638494491577\n",
      "epoch 26, batch 20, current loss 0.621660253405571\n",
      "epoch 26, batch 30, current loss 0.736054790019989\n",
      "epoch 27, batch 10, current loss 0.6842702865600586\n",
      "epoch 27, batch 20, current loss 0.7232145607471466\n",
      "epoch 27, batch 30, current loss 0.7757417678833007\n",
      "epoch 28, batch 10, current loss 0.6609178334474564\n",
      "epoch 28, batch 20, current loss 0.7729113280773163\n",
      "epoch 28, batch 30, current loss 0.6310370206832886\n",
      "epoch 29, batch 10, current loss 0.6947433710098266\n",
      "epoch 29, batch 20, current loss 0.727396547794342\n",
      "epoch 29, batch 30, current loss 0.6528298109769821\n",
      "epoch 30, batch 10, current loss 0.6592960268259048\n",
      "epoch 30, batch 20, current loss 0.5653255969285965\n",
      "epoch 30, batch 30, current loss 0.6890645951032639\n",
      "epoch 31, batch 10, current loss 0.7025429964065552\n",
      "epoch 31, batch 20, current loss 0.7792464196681976\n",
      "epoch 31, batch 30, current loss 0.7359310686588287\n",
      "epoch 32, batch 10, current loss 0.668628454208374\n",
      "epoch 32, batch 20, current loss 0.7644591808319092\n",
      "epoch 32, batch 30, current loss 0.6614588439464569\n",
      "epoch 33, batch 10, current loss 0.6594109863042832\n",
      "epoch 33, batch 20, current loss 0.624619773030281\n",
      "epoch 33, batch 30, current loss 0.7240166634321212\n",
      "epoch 34, batch 10, current loss 0.6133180648088455\n",
      "epoch 34, batch 20, current loss 0.6965667396783829\n",
      "epoch 34, batch 30, current loss 0.6613604575395584\n",
      "epoch 35, batch 10, current loss 0.7255566000938416\n",
      "epoch 35, batch 20, current loss 0.6360229343175888\n",
      "epoch 35, batch 30, current loss 0.6692905783653259\n",
      "epoch 36, batch 10, current loss 0.6660044133663178\n",
      "epoch 36, batch 20, current loss 0.7264989346265793\n",
      "epoch 36, batch 30, current loss 0.6070703387260437\n",
      "epoch 37, batch 10, current loss 0.6455505430698395\n",
      "epoch 37, batch 20, current loss 0.5943929731845856\n",
      "epoch 37, batch 30, current loss 0.670560485124588\n",
      "epoch 38, batch 10, current loss 0.6578366309404373\n",
      "epoch 38, batch 20, current loss 0.6850791215896607\n",
      "epoch 38, batch 30, current loss 0.6777899742126465\n",
      "epoch 39, batch 10, current loss 0.6338773518800735\n",
      "epoch 39, batch 20, current loss 0.6730863630771637\n",
      "epoch 39, batch 30, current loss 0.6630003809928894\n",
      "epoch 40, batch 10, current loss 0.6459503680467605\n",
      "epoch 40, batch 20, current loss 0.7177795231342315\n",
      "epoch 40, batch 30, current loss 0.6222705572843552\n",
      "epoch 41, batch 10, current loss 0.6197230488061904\n",
      "epoch 41, batch 20, current loss 0.5616550594568253\n",
      "epoch 41, batch 30, current loss 0.6583459913730622\n",
      "epoch 42, batch 10, current loss 0.6500959366559982\n",
      "epoch 42, batch 20, current loss 0.6626408487558365\n",
      "epoch 42, batch 30, current loss 0.6453221827745438\n",
      "epoch 43, batch 10, current loss 0.67912577688694\n",
      "epoch 43, batch 20, current loss 0.7360830992460251\n",
      "epoch 43, batch 30, current loss 0.5625700294971466\n",
      "epoch 44, batch 10, current loss 0.7029601335525513\n",
      "epoch 44, batch 20, current loss 0.6427666038274765\n",
      "epoch 44, batch 30, current loss 0.5835584431886673\n",
      "epoch 45, batch 10, current loss 0.6713834017515182\n",
      "epoch 45, batch 20, current loss 0.6198461532592774\n",
      "epoch 45, batch 30, current loss 0.5889921247959137\n",
      "epoch 46, batch 10, current loss 0.5718556225299836\n",
      "epoch 46, batch 20, current loss 0.6655832648277282\n",
      "epoch 46, batch 30, current loss 0.6369630366563797\n",
      "epoch 47, batch 10, current loss 0.6654872119426727\n",
      "epoch 47, batch 20, current loss 0.617427921295166\n",
      "epoch 47, batch 30, current loss 0.6047774225473403\n",
      "epoch 48, batch 10, current loss 0.6612489581108093\n",
      "epoch 48, batch 20, current loss 0.6552136182785034\n",
      "epoch 48, batch 30, current loss 0.5615816801786423\n",
      "epoch 49, batch 10, current loss 0.6003108024597168\n",
      "epoch 49, batch 20, current loss 0.6438125461339951\n",
      "epoch 49, batch 30, current loss 0.5952078521251678\n",
      "epoch 50, batch 10, current loss 0.5505448311567307\n",
      "epoch 50, batch 20, current loss 0.6000777244567871\n",
      "epoch 50, batch 30, current loss 0.6289115369319915\n",
      "epch 50 train accuracy: \n",
      "total_num:468, test accuracy:0.7264957264957265, positive_acc:0.756544502617801, negative_acc:0.5930232558139535\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-3c561fadc0b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epch {} train accuracy: '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mtrain_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mget_confusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"-------------------\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epch {} test accuracy: '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-16-c1b4edbd32c9>\u001b[0m in \u001b[0;36mget_confusion_matrix\u001b[0;34m(true_predicted_labels)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mtest_dic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_predicted_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_dic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mtest_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m             \u001b[0mcross_table\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32melif\u001b[0m  \u001b[0mtest_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mtest_dic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "\n",
    "num_epochs = 350\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([3.5,1.0]).to(device))\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "print('choose SGD as optimizer')\n",
    "#optimizer = optim.Adam(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "#print('choose Adam as optimizer')\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    scheduler.step()\n",
    "    \n",
    "    Mouse_dataset = Mouse_sub_volumes(train_data, transform=transforms.Compose([Flip()]))\n",
    "    dataloader = DataLoader(Mouse_dataset, batch_size=12, shuffle=True, num_workers=4, drop_last = True)\n",
    "    train(net, device, dataloader, optimizer, criterion, epoch)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print('epoch {} train accuracy: '.format(epoch+1))\n",
    "        train_Mouse_dataset = Mouse_sub_volumes(train_data)\n",
    "        train_dataloader = DataLoader(train_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "        train_dic = test(net, device, train_dataloader)\n",
    "        get_confusion_matrix(train_dic)\n",
    "        \n",
    "        print(\"-------------------\")\n",
    "        print('epoch {} test accuracy: '.format(epoch+1))\n",
    "        test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "        test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "        test_dic = test(net, device, test_dataloader)\n",
    "        get_confusion_matrix(test_dic)\n",
    "        \n",
    "        torch.save(net.state_dict(), './model/mut_clas_2019_01_17_e{}.pth'.format(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n",
      "There are 395298 parameters in the model\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_probability(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            outputs = F.softmax(outputs)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy(), outputs.cpu().numpy()[0,0], outputs.cpu().numpy()[0,1]))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), './model/mut_clas_2019_01_15.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./model/mut_clas_2019_01_17_e350.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('train accuracy: ')\n",
    "# Mouse_dataset = Mouse_sub_volumes(all_train_data,train_idx)\n",
    "# train_dataloader = DataLoader(Mouse_dataset, batch_size=128,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "# test(net, device, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zq415/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:19: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:96, test accuracy:0.9375, positive_acc:0.9487179487179487, negative_acc:0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "print('test accuracy: ')\n",
    "Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dic = test_with_probability(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 16.   2.]\n",
      " [  4.  74.]]\n",
      "[0, 90]\n",
      "[16, 32, 45, 46]\n"
     ]
    }
   ],
   "source": [
    "cross_table = np.zeros([2,2])\n",
    "mut_to_nor = []\n",
    "nor_to_mul = []\n",
    "\n",
    "for i in range(len(test_dic)):\n",
    "    if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "        cross_table[0,0] += 1\n",
    "    elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "        cross_table[0,1] += 1\n",
    "        mut_to_nor.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "        cross_table[1,0] += 1\n",
    "        nor_to_mul.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "        cross_table[1,1] += 1\n",
    "print(cross_table)\n",
    "print(mut_to_nor)\n",
    "print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([0]), array([1]), 0.014204379, 0.98579562),\n",
       " (array([1]), array([1]), 0.008861592, 0.9911384),\n",
       " (array([1]), array([1]), 0.0020978176, 0.99790215),\n",
       " (array([1]), array([1]), 0.00019172154, 0.99980825),\n",
       " (array([1]), array([1]), 0.0045706001, 0.9954294),\n",
       " (array([1]), array([1]), 0.0028623149, 0.99713767),\n",
       " (array([1]), array([1]), 9.5042788e-06, 0.99999046),\n",
       " (array([1]), array([1]), 0.0032477456, 0.99675226),\n",
       " (array([1]), array([1]), 0.0064804694, 0.99351948),\n",
       " (array([0]), array([0]), 0.59785759, 0.40214238),\n",
       " (array([1]), array([1]), 0.00016109479, 0.99983883),\n",
       " (array([1]), array([1]), 0.0001081415, 0.99989188),\n",
       " (array([1]), array([1]), 0.0017415026, 0.99825853),\n",
       " (array([1]), array([1]), 0.00043563324, 0.99956435),\n",
       " (array([1]), array([1]), 0.01604772, 0.98395222),\n",
       " (array([1]), array([1]), 0.004320879, 0.9956792),\n",
       " (array([1]), array([0]), 0.89634043, 0.10365963),\n",
       " (array([1]), array([1]), 0.0070954543, 0.9929046),\n",
       " (array([1]), array([1]), 0.0014228453, 0.99857712),\n",
       " (array([1]), array([1]), 0.00067590369, 0.99932408),\n",
       " (array([1]), array([1]), 0.00030585064, 0.99969423),\n",
       " (array([1]), array([1]), 0.000807865, 0.99919218),\n",
       " (array([1]), array([1]), 0.0047491067, 0.99525094),\n",
       " (array([1]), array([1]), 0.0015410857, 0.99845886),\n",
       " (array([1]), array([1]), 0.0017248621, 0.99827516),\n",
       " (array([1]), array([1]), 0.00093266799, 0.99906737),\n",
       " (array([1]), array([1]), 0.00696126, 0.99303871),\n",
       " (array([1]), array([1]), 0.00062795694, 0.99937207),\n",
       " (array([0]), array([0]), 0.9984073, 0.001592725),\n",
       " (array([1]), array([1]), 0.0010237576, 0.99897623),\n",
       " (array([1]), array([1]), 0.0036338919, 0.99636614),\n",
       " (array([1]), array([1]), 0.00539013, 0.99460983),\n",
       " (array([1]), array([0]), 0.91040832, 0.089591704),\n",
       " (array([1]), array([1]), 0.0027843814, 0.99721563),\n",
       " (array([0]), array([0]), 0.99969101, 0.00030905206),\n",
       " (array([0]), array([0]), 0.99097824, 0.0090217199),\n",
       " (array([0]), array([0]), 0.99994278, 5.7214485e-05),\n",
       " (array([1]), array([1]), 0.2358592, 0.76414084),\n",
       " (array([1]), array([1]), 0.037678048, 0.962322),\n",
       " (array([0]), array([0]), 0.99738771, 0.0026122672),\n",
       " (array([1]), array([1]), 0.0057507176, 0.99424922),\n",
       " (array([1]), array([1]), 0.00021831781, 0.99978167),\n",
       " (array([1]), array([1]), 0.00010308383, 0.99989688),\n",
       " (array([1]), array([1]), 0.14635544, 0.85364455),\n",
       " (array([0]), array([0]), 0.99403173, 0.0059682727),\n",
       " (array([1]), array([0]), 0.57051492, 0.42948514),\n",
       " (array([1]), array([0]), 0.85909241, 0.14090754),\n",
       " (array([1]), array([1]), 0.00035839956, 0.99964154),\n",
       " (array([1]), array([1]), 0.0065696584, 0.99343032),\n",
       " (array([1]), array([1]), 0.0068601673, 0.9931398),\n",
       " (array([1]), array([1]), 0.0010310236, 0.99896896),\n",
       " (array([1]), array([1]), 0.037262347, 0.96273768),\n",
       " (array([1]), array([1]), 0.007218787, 0.99278122),\n",
       " (array([1]), array([1]), 0.00038142895, 0.99961853),\n",
       " (array([1]), array([1]), 0.00072305091, 0.99927694),\n",
       " (array([1]), array([1]), 0.00068870059, 0.99931133),\n",
       " (array([1]), array([1]), 0.0048616095, 0.99513841),\n",
       " (array([1]), array([1]), 0.37687516, 0.62312484),\n",
       " (array([1]), array([1]), 0.00086975232, 0.99913031),\n",
       " (array([1]), array([1]), 0.0011815543, 0.99881846),\n",
       " (array([0]), array([0]), 0.99796617, 0.0020338499),\n",
       " (array([0]), array([0]), 0.99949181, 0.00050813088),\n",
       " (array([0]), array([0]), 0.96798778, 0.032012206),\n",
       " (array([0]), array([0]), 0.99847406, 0.0015259309),\n",
       " (array([1]), array([1]), 0.00079022779, 0.99920976),\n",
       " (array([1]), array([1]), 0.0029909613, 0.9970091),\n",
       " (array([0]), array([0]), 0.96524751, 0.034752518),\n",
       " (array([1]), array([1]), 0.083634891, 0.91636515),\n",
       " (array([1]), array([1]), 0.00034653774, 0.99965346),\n",
       " (array([1]), array([1]), 0.0021283673, 0.99787164),\n",
       " (array([1]), array([1]), 0.0005886876, 0.99941134),\n",
       " (array([1]), array([1]), 0.00059245666, 0.99940753),\n",
       " (array([1]), array([1]), 0.00027987055, 0.99972016),\n",
       " (array([1]), array([1]), 0.16132624, 0.83867377),\n",
       " (array([0]), array([0]), 0.98612452, 0.013875498),\n",
       " (array([1]), array([1]), 0.013596511, 0.98640347),\n",
       " (array([1]), array([1]), 0.00020706729, 0.99979299),\n",
       " (array([1]), array([1]), 0.00029030253, 0.99970967),\n",
       " (array([0]), array([0]), 0.9943679, 0.0056321048),\n",
       " (array([1]), array([1]), 0.0023576771, 0.99764234),\n",
       " (array([1]), array([1]), 0.002012217, 0.99798775),\n",
       " (array([1]), array([1]), 0.0018978717, 0.99810213),\n",
       " (array([1]), array([1]), 0.00010765833, 0.99989235),\n",
       " (array([1]), array([1]), 0.00031416977, 0.99968588),\n",
       " (array([1]), array([1]), 0.002023658, 0.99797636),\n",
       " (array([1]), array([1]), 0.00031594042, 0.9996841),\n",
       " (array([0]), array([0]), 0.99251997, 0.0074800821),\n",
       " (array([1]), array([1]), 0.0018715077, 0.99812847),\n",
       " (array([0]), array([0]), 0.98569959, 0.014300473),\n",
       " (array([1]), array([1]), 0.0018904182, 0.99810958),\n",
       " (array([0]), array([1]), 0.045365732, 0.95463425),\n",
       " (array([1]), array([1]), 0.00039051918, 0.99960953),\n",
       " (array([1]), array([1]), 0.00071780599, 0.99928218),\n",
       " (array([1]), array([1]), 0.0076428745, 0.99235713),\n",
       " (array([1]), array([1]), 0.0020680637, 0.99793196),\n",
       " (array([1]), array([1]), 0.0067980145, 0.99320203)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "90\n"
     ]
    }
   ],
   "source": [
    "for i in mut_to_nor:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/mul_img{}.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n",
      "32\n",
      "45\n",
      "46\n"
     ]
    }
   ],
   "source": [
    "for i in nor_to_mul:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/nor_img{}.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    if test_data[i][1] == 0:\n",
    "        img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "        img_save_data_path = './img/mul_img{}.nii'.format(i)\n",
    "        nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make input tensor require gradient\n",
    "    X.requires_grad_()\n",
    "    ##############################################################################\n",
    "    # Perform a forward and backward pass through the model to compute the gradient \n",
    "    # of the correct class score with respect to each input image. You first want \n",
    "    # to compute the loss over the correct scores (we'll combine losses across a batch\n",
    "    # by summing), and then compute the gradients with a backward pass.\n",
    "    ##############################################################################\n",
    "    scores = model(X)\n",
    "    \n",
    "    # Get the correct class computed scores.\n",
    "    scores = scores.gather(1, y.view(-1, 1)).squeeze()  \n",
    "    \n",
    "    # Backward pass, need to supply initial gradients of same tensor shape as scores.\n",
    "    scores.backward(torch.tensor(10.0).cuda(device))\n",
    "    \n",
    "    # Get gradient for image.\n",
    "    saliency = X.grad.data\n",
    "    \n",
    "    # Convert from 3d to 1d.\n",
    "    saliency = saliency.abs()\n",
    "    saliency = saliency.squeeze()\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    saliency = compute_saliency_maps(inputs, labels, net)\n",
    "    \n",
    "    max_value = torch.max(saliency)\n",
    "    saliency[saliency >= (max_value*0.2)] = 1\n",
    "    saliency[saliency < (max_value*0.2)] = 0\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.cpu().detach().numpy()+0.5),np.eye(4))\n",
    "    img_save_data_path = './saliency_map/img_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency.cpu().numpy()),np.eye(4))\n",
    "    saliency_save_data_path = './saliency_map/salency_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.2944)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.max(saliency).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = torch.max(saliency)\n",
    "saliency[saliency >= (max_value*0.2)] = 1\n",
    "saliency[saliency < (max_value*0.2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
