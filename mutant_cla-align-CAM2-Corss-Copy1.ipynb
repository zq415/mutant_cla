{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "from scipy import ndimage\n",
    "import pickle\n",
    "import nibabel as nib\n",
    "import random\n",
    "from scipy.ndimage.interpolation import zoom\n",
    "import copy\n",
    "import Levenshtein\n",
    "\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def read_mutant_txt(path):\n",
    "    name_list = []\n",
    "    fo = open(path)\n",
    "    for line in fo:\n",
    "        striped_line = line.strip('\\n')\n",
    "        if striped_line != '':\n",
    "            name_list.append(striped_line)\n",
    "    return name_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_names = read_mutant_txt('mutant_imgs.txt')\n",
    "data_base_path = '/scratch/zq415/grammar_cor/mutant_detect/data'\n",
    "data_folder_list = ['20180419_newdata_nii_with_filtered', 'new_data_20180522_nii', 'organized_data_nii']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mutant_label[i] = (i, 1, bv_base_name, label_resized, img_resized, img_path[1])\n",
    "\n",
    "save_name = 'All_data_112_64_64.pickle'\n",
    "\n",
    "with open(os.path.join(os.getcwd(),'data',save_name), \"rb\") as input_file:\n",
    "    all_train_data = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  0 25\n",
      "fold  1 18\n",
      "fold  2 17\n",
      "fold  3 13\n",
      "fold  4 15\n",
      "fold  5 15\n"
     ]
    }
   ],
   "source": [
    "mutant_group = [(9,10), (12,13,14), (16,17,18,19), (36,37), (38,39), (42,43), (44,45,46,47), (48,49,50,51), (52,53), (54,55),\n",
    "(56,57,58), (59,60,61), (63,64), (66,67,68), (69,70,71), (73,74), (75,76), (77,78,79), (80,81,82,83,84,85,86,87),\n",
    "(89,90), (91,92), (93,94), (95,96,97), (98,99), (100,101,102)]\n",
    "\n",
    "group_list = []\n",
    "for one_group in mutant_group:\n",
    "    for ii in range(len(one_group)):\n",
    "        group_list.append(one_group[ii])\n",
    "single_mutant = [i for i in range(len(mutant_names)) if i not in group_list]\n",
    "\n",
    "test_mut_names = {}\n",
    "for fold_num in range(6):\n",
    "    test_mut_names[fold_num] = []\n",
    "    for i in range(fold_num,len(mutant_group),6):\n",
    "        for ii in range(len(mutant_group[i])):\n",
    "            test_mut_names[fold_num].append(mutant_names[mutant_group[i][ii]])\n",
    "\n",
    "    for i in range(fold_num,len(single_mutant),6):\n",
    "        test_mut_names[fold_num].append(mutant_names[single_mutant[i]])\n",
    "\n",
    "    print('fold ', fold_num, len(test_mut_names[fold_num]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mutant_img = {}\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] in mutant_names:\n",
    "        mutant_img[all_train_data[i][2]] = (all_train_data[i][3] - 0.5, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_names = []\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] not in mutant_names:\n",
    "        normal_names.append(all_train_data[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_group = []\n",
    "indexed_list = []\n",
    "group_num = 0\n",
    "for i in range(len(normal_names)):\n",
    "    if i not in indexed_list:\n",
    "        normal_group.append([normal_names[i]])\n",
    "        indexed_list.append(i)\n",
    "        for ii in range(i+1,len(normal_names)):\n",
    "            if ii not in indexed_list and Levenshtein.distance(normal_names[i], normal_names[ii]) < 2:\n",
    "                normal_group[group_num].append(normal_names[ii])\n",
    "                indexed_list.append(ii)\n",
    "                \n",
    "        group_num += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold  0 76\n",
      "fold  1 91\n",
      "fold  2 72\n",
      "fold  3 67\n",
      "fold  4 71\n",
      "fold  5 86\n"
     ]
    }
   ],
   "source": [
    "test_normal_names = {}\n",
    "for fold_num in range(6):\n",
    "    test_normal_names[fold_num] = []\n",
    "    for i in range(fold_num,len(normal_group),6):\n",
    "        for ii in range(len(normal_group[i])):\n",
    "            test_normal_names[fold_num].append(normal_group[i][ii])\n",
    "\n",
    "    print('fold ', fold_num, len(test_normal_names[fold_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "normal_img = {}\n",
    "for i in range(len(all_train_data)):\n",
    "    if all_train_data[i][2] not in mutant_names:\n",
    "        normal_img[all_train_data[i][5]] = (all_train_data[i][3] - 0.5, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fold:  0 101\n",
      "fold:  1 109\n",
      "fold:  2 89\n",
      "fold:  3 80\n",
      "fold:  4 86\n",
      "fold:  5 101\n"
     ]
    }
   ],
   "source": [
    "data_folds = [[],[],[],[],[],[]]\n",
    "\n",
    "for fold_num in range(6):\n",
    "    \n",
    "    for i in range(len(test_mut_names[fold_num])):\n",
    "        data_folds[fold_num].append(mutant_img[test_mut_names[fold_num][i]])\n",
    "        \n",
    "    for i in range(len(test_normal_names[fold_num])):\n",
    "        data_folds[fold_num].append(normal_img[test_normal_names[fold_num][i]])\n",
    "\n",
    "    print('fold: ', fold_num, len(data_folds[fold_num]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class Mouse_sub_volumes(Dataset):\n",
    "    \"\"\"Mouse sub-volumes BV dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, all_data , transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            all_whole_volumes: Contain all the padded whole BV volumes as a dic\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.all_data = all_data\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.all_data)\n",
    "\n",
    "    def __getitem__(self, num):\n",
    "        \n",
    "        current_img, label = self.all_data[num]\n",
    "        \n",
    "        img = np.float32(current_img[np.newaxis,...])\n",
    "        sample = {'image': img, 'label': label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flip(object):\n",
    "    \n",
    "    \"\"\"\n",
    "    Flip the image for data augmentation, but prefer original image.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,ori_probability=0.20):\n",
    "        self.ori_probability = ori_probability\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        if random.uniform(0,1) < self.ori_probability:\n",
    "            return sample\n",
    "        else:\n",
    "            img, label = sample['image'], sample['label']\n",
    "            random_choise1=random.choice([1,2,3,4,5,6,7,8])\n",
    "            img[0,...] = {1: lambda x: x,\n",
    "                          2: lambda x: x[::-1,:,:],\n",
    "                          3: lambda x: x[:,::-1,:],\n",
    "                          4: lambda x: x[:,:,::-1],\n",
    "                          5: lambda x: x[::-1,::-1,:],\n",
    "                          6: lambda x: x[::-1,:,::-1],\n",
    "                          7: lambda x: x[:,::-1,::-1],\n",
    "                          8: lambda x: x[::-1,::-1,::-1]\n",
    "                          }[random_choise1](img[0,...])\n",
    "        return {'image': img, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    def __init__(self,conv_drop_rate=0.10,linear_drop_rate=0.2):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.conv1 = nn.Conv3d(in_channels=1, out_channels=12, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv1_bn = nn.BatchNorm3d(12)\n",
    "        self.conv2 = nn.Conv3d(in_channels=12, out_channels=12, kernel_size=3,stride=1,padding=2, dilation=2)\n",
    "        self.conv2_bn = nn.BatchNorm3d(12)\n",
    "        self.pool1 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout1 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv3 = nn.Conv3d(in_channels=12, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv3_bn = nn.BatchNorm3d(24)\n",
    "        self.conv4 = nn.Conv3d(in_channels=24, out_channels=24, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv4_bn = nn.BatchNorm3d(24)\n",
    "        self.pool2 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout2 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv5 = nn.Conv3d(in_channels=24, out_channels=48, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv5_bn = nn.BatchNorm3d(48)\n",
    "        self.conv6 = nn.Conv3d(in_channels=48, out_channels=48, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv6_bn = nn.BatchNorm3d(48)\n",
    "        self.pool3 = nn.MaxPool3d(2, 2)\n",
    "        self.dropout3 = nn.Dropout3d(conv_drop_rate)\n",
    "        \n",
    "        self.conv7 = nn.Conv3d(in_channels=48, out_channels=72, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv7_bn = nn.BatchNorm3d(72)\n",
    "        self.conv8 = nn.Conv3d(in_channels=72, out_channels=72, kernel_size=3,stride=1, padding=2,dilation=2)\n",
    "        self.conv8_bn = nn.BatchNorm3d(72)\n",
    "        self.pool4 = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.dropout4 = nn.Dropout3d(linear_drop_rate)\n",
    "        self.pool5 = nn.AdaptiveAvgPool3d((1,1,1))\n",
    "        self.dropout5 = nn.Dropout3d(linear_drop_rate)\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(144, 2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1_bn(F.relu(self.conv1(x)))\n",
    "        x = self.dropout1(self.pool1(self.conv2_bn(F.relu(self.conv2(x)))))\n",
    "        \n",
    "        x = self.conv3_bn(F.relu(self.conv3(x)))\n",
    "        x = self.dropout2(self.pool2(self.conv4_bn(F.relu(self.conv4(x)))))\n",
    "        \n",
    "        x = self.conv5_bn(F.relu(self.conv5(x)))\n",
    "        x = self.dropout3(self.pool3(self.conv6_bn(F.relu(self.conv6(x)))))\n",
    "        \n",
    "        x = self.conv7_bn(F.relu(self.conv7(x)))\n",
    "        x = self.conv8_bn(F.relu(self.conv8(x)))\n",
    "        \n",
    "        x1 = self.dropout4(self.pool4(x))\n",
    "        x2 = self.dropout5(self.pool5(x))\n",
    "        \n",
    "        x1 = x1.view(-1, 72)\n",
    "        x2 = x2.view(-1, 72)\n",
    "        x = torch.cat((x1, x2), 1)\n",
    "        #x = self.dropout5(self.fc1_bn(F.relu(self.fc1(x))))\n",
    "        x = self.fc1(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, criterion, epoch):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i_batch, sample_batched in enumerate(train_loader):\n",
    "        inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(inputs.shape)\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        i_batch += 1\n",
    "        if i_batch % 10 == 0:\n",
    "            print(\"epoch {}, batch {}, current loss {}\".format(epoch+1,i_batch,running_loss/10))\n",
    "            running_loss = 0.0\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy()))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels\n",
    "\n",
    "def get_confusion_matrix(true_predicted_labels):\n",
    "    cross_table = np.zeros([2,2])\n",
    "    mut_to_nor = []\n",
    "    nor_to_mul = []\n",
    "    test_dic = true_predicted_labels\n",
    "    for i in range(len(test_dic)):\n",
    "        if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "            cross_table[0,0] += 1\n",
    "        elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "            cross_table[0,1] += 1\n",
    "            mut_to_nor.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "            cross_table[1,0] += 1\n",
    "            nor_to_mul.append(i)\n",
    "        elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "            cross_table[1,1] += 1\n",
    "    print(cross_table)\n",
    "    print(mut_to_nor)\n",
    "    print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "choose SGD as optimizer\n",
      "There are 355358 parameters in the model\n",
      "test_data_length: 101 train_data_length: 465\n",
      "epoch 1, batch 10, current loss 0.6973104119300843\n",
      "epoch 1, batch 20, current loss 0.7014976263046264\n",
      "epoch 1, batch 30, current loss 0.6946639001369477\n",
      "fold 0, epoch 1 train accuracy: \n",
      "total_num:465, test accuracy:0.832258064516129, positive_acc:1.0, negative_acc:0.0\n",
      "[[   0.   78.]\n",
      " [   0.  387.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378]\n",
      "[]\n",
      "-------------------\n",
      "fold 0, epoch 1 test accuracy: \n",
      "total_num:109, test accuracy:0.8348623853211009, positive_acc:1.0, negative_acc:0.0\n",
      "[[  0.  18.]\n",
      " [  0.  91.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[]\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "There are 355358 parameters in the model\n",
      "test_data_length: 109 train_data_length: 457\n",
      "epoch 1, batch 10, current loss 0.6967957198619843\n",
      "epoch 1, batch 20, current loss 0.6964114964008331\n",
      "epoch 1, batch 30, current loss 0.6986576795578003\n",
      "fold 1, epoch 1 train accuracy: \n",
      "total_num:457, test accuracy:0.8140043763676149, positive_acc:1.0, negative_acc:0.0\n",
      "[[   0.   85.]\n",
      " [   0.  372.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370]\n",
      "[]\n",
      "-------------------\n",
      "fold 1, epoch 1 test accuracy: \n",
      "total_num:109, test accuracy:0.8348623853211009, positive_acc:1.0, negative_acc:0.0\n",
      "[[  0.  18.]\n",
      " [  0.  91.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[]\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "There are 355358 parameters in the model\n",
      "test_data_length: 89 train_data_length: 477\n",
      "epoch 1, batch 10, current loss 0.6997758746147156\n",
      "epoch 1, batch 20, current loss 0.7095937848091125\n",
      "epoch 1, batch 30, current loss 0.6978279888629914\n",
      "fold 2, epoch 1 train accuracy: \n",
      "total_num:477, test accuracy:0.18029350104821804, positive_acc:0.0, negative_acc:1.0\n",
      "[[  86.    0.]\n",
      " [ 391.    0.]]\n",
      "[]\n",
      "[25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 391, 392, 393, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476]\n",
      "-------------------\n",
      "fold 2, epoch 1 test accuracy: \n",
      "total_num:109, test accuracy:0.1651376146788991, positive_acc:0.0, negative_acc:1.0\n",
      "[[ 18.   0.]\n",
      " [ 91.   0.]]\n",
      "[]\n",
      "[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108]\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "There are 355358 parameters in the model\n",
      "test_data_length: 80 train_data_length: 486\n",
      "epoch 1, batch 10, current loss 0.6977521419525147\n",
      "epoch 1, batch 20, current loss 0.7018866062164306\n",
      "epoch 1, batch 30, current loss 0.7027559697628021\n",
      "epoch 1, batch 40, current loss 0.6983835518360137\n",
      "fold 3, epoch 1 train accuracy: \n",
      "total_num:486, test accuracy:0.8148148148148148, positive_acc:1.0, negative_acc:0.0\n",
      "[[   0.   90.]\n",
      " [   0.  396.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 385, 386, 387, 388, 389, 390, 391, 392, 393, 394, 395, 396, 397, 398, 399]\n",
      "[]\n",
      "-------------------\n",
      "fold 3, epoch 1 test accuracy: \n",
      "total_num:109, test accuracy:0.8348623853211009, positive_acc:1.0, negative_acc:0.0\n",
      "[[  0.  18.]\n",
      " [  0.  91.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[]\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "There are 355358 parameters in the model\n",
      "test_data_length: 86 train_data_length: 480\n",
      "epoch 1, batch 10, current loss 0.6982418060302734\n",
      "epoch 1, batch 20, current loss 0.6915932595729828\n",
      "epoch 1, batch 30, current loss 0.7000394344329834\n",
      "epoch 1, batch 40, current loss 0.6925236225128174\n",
      "fold 4, epoch 1 train accuracy: \n",
      "total_num:480, test accuracy:0.18333333333333332, positive_acc:0.0, negative_acc:1.0\n",
      "[[  88.    0.]\n",
      " [ 392.    0.]]\n",
      "[]\n",
      "[25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331, 332, 333, 334, 335, 336, 337, 338, 339, 340, 341, 342, 343, 344, 345, 346, 347, 348, 349, 350, 351, 352, 353, 354, 355, 356, 357, 358, 359, 360, 361, 362, 363, 364, 365, 366, 367, 368, 369, 370, 371, 372, 373, 374, 375, 376, 377, 378, 394, 395, 396, 397, 398, 399, 400, 401, 402, 403, 404, 405, 406, 407, 408, 409, 410, 411, 412, 413, 414, 415, 416, 417, 418, 419, 420, 421, 422, 423, 424, 425, 426, 427, 428, 429, 430, 431, 432, 433, 434, 435, 436, 437, 438, 439, 440, 441, 442, 443, 444, 445, 446, 447, 448, 449, 450, 451, 452, 453, 454, 455, 456, 457, 458, 459, 460, 461, 462, 463, 464, 465, 466, 467, 468, 469, 470, 471, 472, 473, 474, 475, 476, 477, 478, 479]\n",
      "-------------------\n",
      "fold 4, epoch 1 test accuracy: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_num:109, test accuracy:0.1651376146788991, positive_acc:0.0, negative_acc:1.0\n",
      "[[ 18.   0.]\n",
      " [ 91.   0.]]\n",
      "[]\n",
      "[18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108]\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n",
      "There are 355358 parameters in the model\n",
      "test_data_length: 101 train_data_length: 465\n",
      "epoch 1, batch 10, current loss 0.698935741186142\n",
      "epoch 1, batch 20, current loss 0.6869503498077393\n",
      "epoch 1, batch 30, current loss 0.7023661434650421\n",
      "fold 5, epoch 1 train accuracy: \n",
      "total_num:465, test accuracy:0.810752688172043, positive_acc:1.0, negative_acc:0.0\n",
      "[[   0.   88.]\n",
      " [   0.  377.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 379, 380, 381, 382, 383, 384, 385, 386, 387, 388, 389, 390, 391, 392, 393]\n",
      "[]\n",
      "-------------------\n",
      "fold 5, epoch 1 test accuracy: \n",
      "total_num:109, test accuracy:0.8348623853211009, positive_acc:1.0, negative_acc:0.0\n",
      "[[  0.  18.]\n",
      " [  0.  91.]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17]\n",
      "[]\n",
      "----------------------------------------------------------\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 1\n",
    "criterion = nn.CrossEntropyLoss(weight=torch.FloatTensor([3.5,1.0]).to(device))\n",
    "\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9, weight_decay=0.00001)\n",
    "print('choose SGD as optimizer')\n",
    "#optimizer = optim.Adam(net.parameters(), lr=args.lr*10, weight_decay=0.00001)\n",
    "#print('choose Adam as optimizer')\n",
    "\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100, gamma=0.5)\n",
    "for fold in range(6):\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    net = VGG_net()\n",
    "    #net.apply(weight_init)\n",
    "    if torch.cuda.device_count() > 1:\n",
    "        print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "        net = nn.DataParallel(net)\n",
    "    net.to(device)\n",
    "    print(\"There are {} parameters in the model\".format(count_parameters(net)))\n",
    "    train_data = []\n",
    "    for i in range(6):\n",
    "        if i == fold:\n",
    "            test_data = data_folds[i]\n",
    "        else:\n",
    "            train_data += data_folds[i]# + data_folds[2] + data_folds[3] + data_folds[4] + data_folds[5]\n",
    "    print('test_data_length:', len(test_data), 'train_data_length:', len(train_data))\n",
    "    test_data = data_folds[1]\n",
    "    for epoch in range(num_epochs):\n",
    "        scheduler.step()\n",
    "\n",
    "        Mouse_dataset = Mouse_sub_volumes(train_data, transform=transforms.Compose([Flip()]))\n",
    "        dataloader = DataLoader(Mouse_dataset, batch_size=12, shuffle=True, num_workers=4, drop_last = True)\n",
    "        train(net, device, dataloader, optimizer, criterion, epoch)\n",
    "        if (epoch + 1) % 1 == 0:\n",
    "            print('fold {}, epoch {} train accuracy: '.format(fold, epoch+1))\n",
    "            train_Mouse_dataset = Mouse_sub_volumes(train_data)\n",
    "            train_dataloader = DataLoader(train_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "            train_dic = test(net, device, train_dataloader)\n",
    "            get_confusion_matrix(train_dic)\n",
    "\n",
    "            print(\"-------------------\")\n",
    "            print('fold {}, epoch {} test accuracy: '.format(fold, epoch+1))\n",
    "            test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "            test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "            test_dic = test(net, device, test_dataloader)\n",
    "            get_confusion_matrix(test_dic)\n",
    "\n",
    "            torch.save(net.state_dict(), './model/mut_clas_2019_01_31_e{}_global2_fold{}.pth'.format(epoch+1,fold))\n",
    "            print(\"----------------------------------------------------------\")\n",
    "            print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "net = VGG_net()\n",
    "#net.apply(weight_init)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "print(\"There are {} parameters in the model\".format(count_parameters(net)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_with_probability(model, device, test_loader):\n",
    "    model.eval()\n",
    "    correct_num = 0\n",
    "    total_num = 0\n",
    "    positive_correct=0\n",
    "    positive_num=0\n",
    "    negative_correct=0\n",
    "    negative_num=0\n",
    "    \n",
    "    true_predicted_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i_batch, sample_batched in enumerate(test_loader):\n",
    "            inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "            inputs = inputs.to(device)\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            outputs = F.softmax(outputs)\n",
    "            true_predicted_labels.append((labels.numpy(), predicted.cpu().numpy(), outputs.cpu().numpy()[0,0], outputs.cpu().numpy()[0,1]))\n",
    "            correct_num+=np.sum(predicted.cpu().numpy()==labels.numpy())\n",
    "            total_num+=len(labels)\n",
    "            positive_correct+=np.sum(predicted.cpu().numpy()*labels.numpy())\n",
    "            positive_num+=np.sum(labels.numpy())\n",
    "            negative_correct+=np.sum((1-predicted.cpu().numpy())*(1-labels.numpy()))\n",
    "            negative_num+=np.sum(1-labels.numpy())\n",
    "            \n",
    "    print('total_num:{}, test accuracy:{}, positive_acc:{}, negative_acc:{}'.format(total_num,\n",
    "                                                                                   correct_num/total_num,\n",
    "                                                                                    positive_correct/positive_num,\n",
    "                                                                                    negative_correct/negative_num\n",
    "                                                                                    ))\n",
    "    return true_predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(net.state_dict(), './model/mut_clas_2019_01_15.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.load_state_dict(torch.load('./model/mut_clas_2019_01_29_e260_global3.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('train accuracy: ')\n",
    "# Mouse_dataset = Mouse_sub_volumes(all_train_data,train_idx)\n",
    "# train_dataloader = DataLoader(Mouse_dataset, batch_size=128,\n",
    "#                         shuffle=False, num_workers=4)\n",
    "# test(net, device, train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test accuracy: ')\n",
    "Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "test_dic = test_with_probability(net, device, test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_table = np.zeros([2,2])\n",
    "mut_to_nor = []\n",
    "nor_to_mul = []\n",
    "\n",
    "for i in range(len(test_dic)):\n",
    "    if test_dic[i][0] ==0 and test_dic[i][1] ==0:\n",
    "        cross_table[0,0] += 1\n",
    "    elif  test_dic[i][0] ==0 and test_dic[i][1] ==1:\n",
    "        cross_table[0,1] += 1\n",
    "        mut_to_nor.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==0:\n",
    "        cross_table[1,0] += 1\n",
    "        nor_to_mul.append(i)\n",
    "    elif test_dic[i][0] ==1 and test_dic[i][1] ==1:\n",
    "        cross_table[1,1] += 1\n",
    "print(cross_table)\n",
    "print(mut_to_nor)\n",
    "print(nor_to_mul)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in mut_to_nor:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/mul_img{}_cam.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in nor_to_mul:\n",
    "    print(i)\n",
    "    img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "    img_save_data_path = './img/nor_img{}_cam.nii'.format(i)\n",
    "    nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_data)):\n",
    "    if test_data[i][1] == 0:\n",
    "        img_nft = nib.Nifti1Image(np.squeeze(test_data[i][0]+0.5),np.eye(4))\n",
    "        img_save_data_path = './img/mul_img{}.nii'.format(i)\n",
    "        nib.save(img_nft,img_save_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_saliency_maps(X, y, model):\n",
    "    \"\"\"\n",
    "    Compute a class saliency map using the model for images X and labels y.\n",
    "\n",
    "    Input:\n",
    "    - X: Input images; Tensor of shape (N, 3, H, W)\n",
    "    - y: Labels for X; LongTensor of shape (N,)\n",
    "    - model: A pretrained CNN that will be used to compute the saliency map.\n",
    "\n",
    "    Returns:\n",
    "    - saliency: A Tensor of shape (N, H, W) giving the saliency maps for the input\n",
    "    images.\n",
    "    \"\"\"\n",
    "    # Make sure the model is in \"test\" mode\n",
    "    model.eval()\n",
    "    \n",
    "    # Make input tensor require gradient\n",
    "    X.requires_grad_()\n",
    "    ##############################################################################\n",
    "    # Perform a forward and backward pass through the model to compute the gradient \n",
    "    # of the correct class score with respect to each input image. You first want \n",
    "    # to compute the loss over the correct scores (we'll combine losses across a batch\n",
    "    # by summing), and then compute the gradients with a backward pass.\n",
    "    ##############################################################################\n",
    "    scores = model(X)\n",
    "    \n",
    "    # Get the correct class computed scores.\n",
    "    scores = scores.gather(1, y.view(-1, 1)).squeeze()  \n",
    "    \n",
    "    # Backward pass, need to supply initial gradients of same tensor shape as scores.\n",
    "    scores.backward(torch.tensor(10.0).cuda(device))\n",
    "    \n",
    "    # Get gradient for image.\n",
    "    saliency = X.grad.data\n",
    "    \n",
    "    # Convert from 3d to 1d.\n",
    "    saliency = saliency.abs()\n",
    "    saliency = saliency.squeeze()\n",
    "    ##############################################################################\n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    saliency = compute_saliency_maps(inputs, labels, net)\n",
    "    \n",
    "    max_value = torch.max(saliency)\n",
    "    saliency[saliency >= (max_value*0.2)] = 1\n",
    "    saliency[saliency < (max_value*0.2)] = 0\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.cpu().detach().numpy()+0.5),np.eye(4))\n",
    "    img_save_data_path = './saliency_map/img_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency.cpu().numpy()),np.eye(4))\n",
    "    saliency_save_data_path = './saliency_map/salency_label{}_{}.nii'.format(labels.cpu().numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(saliency).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value = torch.max(saliency)\n",
    "saliency[saliency >= (max_value*0.2)] = 1\n",
    "saliency[saliency < (max_value*0.2)] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.fc1.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputs= []\n",
    "# def hook(module, input, output):\n",
    "#     outputs.append(output)\n",
    "\n",
    "# net.conv8_bn.register_forward_hook(hook)\n",
    "# out = net(res)\n",
    "# out = net(res1)\n",
    "# print(outputs)\n",
    "\n",
    "\n",
    "# test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "# test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "# for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "#     inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "#     inputs = inputs.to(device)\n",
    "#     labels = labels.to(device)\n",
    "#     saliency = compute_saliency_maps(inputs, labels, net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cpu()\n",
    "net.eval()\n",
    "\n",
    "fc_weight = net.fc1.weight.data\n",
    "\n",
    "res50_conv = nn.Sequential(*list(net.children())[:-3])\n",
    "for param in res50_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']  \n",
    "    saliency = compute_cam_maps(inputs, labels, net, fc_weight, res50_conv)\n",
    "    \n",
    "#     max_value = np.max(saliency)\n",
    "#     saliency[saliency >= (max_value*0.2)] = 1\n",
    "#     saliency[saliency < (max_value*0.2)] = 0\n",
    "    \n",
    "    img_nft = nib.Nifti1Image(np.squeeze(inputs.numpy()+0.5),np.eye(4))\n",
    "    img_save_data_path = './cam_map/img_label{}_{}.nii'.format(labels.numpy()[0], i_batch)\n",
    "    nib.save(img_nft,img_save_data_path)\n",
    "    \n",
    "    saliency_nft = nib.Nifti1Image(np.squeeze(saliency),np.eye(4))\n",
    "    saliency_save_data_path = './cam_map/salency_label{}_{}.nii'.format(labels.numpy()[0], i_batch)\n",
    "    nib.save(saliency_nft,saliency_save_data_path)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cam represent class saliency map\n",
    "def compute_cam_maps(X, y, model, fc_weight, feature_extract): \n",
    "    model.eval()\n",
    "    \n",
    "    outputs = feature_extract(X).squeeze()\n",
    "    channels = outputs.shape[0]\n",
    "    saliency = outputs[0,...] * fc_weight[y, 0]\n",
    "    for i in range(1,channels):\n",
    "        saliency += outputs[i,...] * fc_weight[y, i]\n",
    "    saliency = zoom(saliency.numpy(), 8)\n",
    "    \n",
    "    saliency = saliency - np.min(saliency)\n",
    "    saliency = saliency / np.max(saliency)\n",
    "    \n",
    "    return saliency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,96):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.cpu()\n",
    "net.eval()\n",
    "\n",
    "fc_weight = net.fc1.weight.data\n",
    "\n",
    "res50_conv = nn.Sequential(*list(net.children())[:-2])\n",
    "for param in res50_conv.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "test_Mouse_dataset = Mouse_sub_volumes(test_data)\n",
    "test_dataloader = DataLoader(test_Mouse_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_dataloader):\n",
    "    inputs, labels = sample_batched['image'], sample_batched['label']\n",
    "    print(res50_conv(inputs).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
